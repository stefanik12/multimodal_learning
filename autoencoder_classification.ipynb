{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-05-26 13:41:32,389 : INFO : collecting all words and their counts\n",
      "2018-05-26 13:41:32,390 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2018-05-26 13:41:32,402 : INFO : collected 3702 word types and 10 unique tags from a corpus of 1503 examples and 65463 words\n",
      "2018-05-26 13:41:32,403 : INFO : Loading a fresh vocabulary\n",
      "2018-05-26 13:41:32,406 : INFO : min_count=5 retains 1058 unique words (28% of original 3702, drops 2644)\n",
      "2018-05-26 13:41:32,407 : INFO : min_count=5 leaves 61217 word corpus (93% of original 65463, drops 4246)\n",
      "2018-05-26 13:41:32,409 : INFO : deleting the raw counts dictionary of 3702 items\n",
      "2018-05-26 13:41:32,410 : INFO : sample=0.001 downsamples 71 most-common words\n",
      "2018-05-26 13:41:32,410 : INFO : downsampling leaves estimated 39737 word corpus (64.9% of prior 61217)\n",
      "2018-05-26 13:41:32,413 : INFO : estimated required memory for 1058 words and 400 dimensions: 3932600 bytes\n",
      "2018-05-26 13:41:32,413 : INFO : resetting layer weights\n",
      "2018-05-26 13:41:32,430 : INFO : training model with 1 workers on 1058 vocabulary and 400 features, using sg=1 hs=0 sample=0.001 negative=12 window=8\n",
      "2018-05-26 13:41:32,563 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-26 13:41:32,564 : INFO : EPOCH - 1 : training on 65463 raw words (41232 effective words) took 0.1s, 313875 effective words/s\n",
      "2018-05-26 13:41:32,697 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-26 13:41:32,698 : INFO : EPOCH - 2 : training on 65463 raw words (41111 effective words) took 0.1s, 310954 effective words/s\n",
      "2018-05-26 13:41:32,829 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-26 13:41:32,830 : INFO : EPOCH - 3 : training on 65463 raw words (41258 effective words) took 0.1s, 317360 effective words/s\n",
      "2018-05-26 13:41:32,962 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-26 13:41:32,963 : INFO : EPOCH - 4 : training on 65463 raw words (41138 effective words) took 0.1s, 313218 effective words/s\n",
      "2018-05-26 13:41:33,093 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-26 13:41:33,094 : INFO : EPOCH - 5 : training on 65463 raw words (41386 effective words) took 0.1s, 320206 effective words/s\n",
      "2018-05-26 13:41:33,226 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-26 13:41:33,227 : INFO : EPOCH - 6 : training on 65463 raw words (41225 effective words) took 0.1s, 314290 effective words/s\n",
      "2018-05-26 13:41:33,356 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-26 13:41:33,356 : INFO : EPOCH - 7 : training on 65463 raw words (41396 effective words) took 0.1s, 324829 effective words/s\n",
      "2018-05-26 13:41:33,484 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-26 13:41:33,485 : INFO : EPOCH - 8 : training on 65463 raw words (41267 effective words) took 0.1s, 325916 effective words/s\n",
      "2018-05-26 13:41:33,616 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-26 13:41:33,617 : INFO : EPOCH - 9 : training on 65463 raw words (41227 effective words) took 0.1s, 316370 effective words/s\n",
      "2018-05-26 13:41:33,747 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-05-26 13:41:33,748 : INFO : EPOCH - 10 : training on 65463 raw words (41149 effective words) took 0.1s, 319190 effective words/s\n",
      "2018-05-26 13:41:33,749 : INFO : training on a 654630 raw words (412389 effective words) took 1.3s, 312962 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>390</th>\n",
       "      <th>391</th>\n",
       "      <th>392</th>\n",
       "      <th>393</th>\n",
       "      <th>394</th>\n",
       "      <th>395</th>\n",
       "      <th>396</th>\n",
       "      <th>397</th>\n",
       "      <th>398</th>\n",
       "      <th>399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000000491008.jpg</th>\n",
       "      <td>0.034389</td>\n",
       "      <td>0.178236</td>\n",
       "      <td>-0.140821</td>\n",
       "      <td>-0.139339</td>\n",
       "      <td>-0.007118</td>\n",
       "      <td>0.009060</td>\n",
       "      <td>0.084266</td>\n",
       "      <td>0.178405</td>\n",
       "      <td>0.029304</td>\n",
       "      <td>-0.112014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037619</td>\n",
       "      <td>0.144960</td>\n",
       "      <td>0.006647</td>\n",
       "      <td>0.028955</td>\n",
       "      <td>0.068747</td>\n",
       "      <td>0.155727</td>\n",
       "      <td>-0.104296</td>\n",
       "      <td>0.038082</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>0.021072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000402433.jpg</th>\n",
       "      <td>0.050274</td>\n",
       "      <td>0.239730</td>\n",
       "      <td>-0.137886</td>\n",
       "      <td>-0.177502</td>\n",
       "      <td>0.029812</td>\n",
       "      <td>0.014745</td>\n",
       "      <td>0.190489</td>\n",
       "      <td>0.213520</td>\n",
       "      <td>0.013288</td>\n",
       "      <td>-0.068929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095179</td>\n",
       "      <td>0.139093</td>\n",
       "      <td>-0.062520</td>\n",
       "      <td>0.044480</td>\n",
       "      <td>0.094899</td>\n",
       "      <td>0.228152</td>\n",
       "      <td>-0.154771</td>\n",
       "      <td>0.008544</td>\n",
       "      <td>0.025904</td>\n",
       "      <td>0.011775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000025603.jpg</th>\n",
       "      <td>0.076880</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>-0.209163</td>\n",
       "      <td>-0.225548</td>\n",
       "      <td>0.027096</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>0.126819</td>\n",
       "      <td>0.202667</td>\n",
       "      <td>-0.033685</td>\n",
       "      <td>-0.123941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048814</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>0.005091</td>\n",
       "      <td>0.111140</td>\n",
       "      <td>0.227810</td>\n",
       "      <td>-0.149922</td>\n",
       "      <td>0.027732</td>\n",
       "      <td>0.085534</td>\n",
       "      <td>0.006732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000385029.jpg</th>\n",
       "      <td>0.103426</td>\n",
       "      <td>0.329491</td>\n",
       "      <td>-0.191061</td>\n",
       "      <td>-0.191092</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.075802</td>\n",
       "      <td>0.184458</td>\n",
       "      <td>0.273794</td>\n",
       "      <td>-0.064881</td>\n",
       "      <td>-0.129843</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052673</td>\n",
       "      <td>0.223536</td>\n",
       "      <td>-0.047499</td>\n",
       "      <td>-0.030998</td>\n",
       "      <td>0.069966</td>\n",
       "      <td>0.292518</td>\n",
       "      <td>-0.148160</td>\n",
       "      <td>0.048956</td>\n",
       "      <td>0.071829</td>\n",
       "      <td>-0.001645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000047112.jpg</th>\n",
       "      <td>0.065815</td>\n",
       "      <td>0.267185</td>\n",
       "      <td>-0.167811</td>\n",
       "      <td>-0.186340</td>\n",
       "      <td>0.025744</td>\n",
       "      <td>0.055847</td>\n",
       "      <td>0.170204</td>\n",
       "      <td>0.212838</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.154392</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042465</td>\n",
       "      <td>0.184114</td>\n",
       "      <td>-0.017194</td>\n",
       "      <td>0.006004</td>\n",
       "      <td>0.118310</td>\n",
       "      <td>0.265148</td>\n",
       "      <td>-0.092132</td>\n",
       "      <td>0.031525</td>\n",
       "      <td>0.103163</td>\n",
       "      <td>0.026644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000260105.jpg</th>\n",
       "      <td>0.070640</td>\n",
       "      <td>0.271789</td>\n",
       "      <td>-0.176954</td>\n",
       "      <td>-0.127800</td>\n",
       "      <td>0.061398</td>\n",
       "      <td>0.059655</td>\n",
       "      <td>0.163175</td>\n",
       "      <td>0.186536</td>\n",
       "      <td>-0.035283</td>\n",
       "      <td>-0.095375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068267</td>\n",
       "      <td>0.175517</td>\n",
       "      <td>-0.041580</td>\n",
       "      <td>0.031629</td>\n",
       "      <td>0.077302</td>\n",
       "      <td>0.223357</td>\n",
       "      <td>-0.107575</td>\n",
       "      <td>0.023528</td>\n",
       "      <td>0.060895</td>\n",
       "      <td>0.024663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000306700.jpg</th>\n",
       "      <td>0.062630</td>\n",
       "      <td>0.252479</td>\n",
       "      <td>-0.158598</td>\n",
       "      <td>-0.164164</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.059722</td>\n",
       "      <td>0.128489</td>\n",
       "      <td>0.233139</td>\n",
       "      <td>-0.014195</td>\n",
       "      <td>-0.137898</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061862</td>\n",
       "      <td>0.183026</td>\n",
       "      <td>-0.015303</td>\n",
       "      <td>-0.015338</td>\n",
       "      <td>0.072456</td>\n",
       "      <td>0.215402</td>\n",
       "      <td>-0.110546</td>\n",
       "      <td>0.064164</td>\n",
       "      <td>0.077507</td>\n",
       "      <td>-0.007365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000179214.jpg</th>\n",
       "      <td>0.010683</td>\n",
       "      <td>0.294232</td>\n",
       "      <td>-0.097603</td>\n",
       "      <td>-0.178310</td>\n",
       "      <td>0.006925</td>\n",
       "      <td>0.075486</td>\n",
       "      <td>0.210692</td>\n",
       "      <td>0.236762</td>\n",
       "      <td>0.000643</td>\n",
       "      <td>-0.151978</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100968</td>\n",
       "      <td>0.146854</td>\n",
       "      <td>-0.013425</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>0.145002</td>\n",
       "      <td>0.277677</td>\n",
       "      <td>-0.060167</td>\n",
       "      <td>0.056858</td>\n",
       "      <td>0.063879</td>\n",
       "      <td>-0.007127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000357903.jpg</th>\n",
       "      <td>0.059414</td>\n",
       "      <td>0.275268</td>\n",
       "      <td>-0.149608</td>\n",
       "      <td>-0.186980</td>\n",
       "      <td>0.034771</td>\n",
       "      <td>0.046625</td>\n",
       "      <td>0.184829</td>\n",
       "      <td>0.241018</td>\n",
       "      <td>-0.012966</td>\n",
       "      <td>-0.131161</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051078</td>\n",
       "      <td>0.180507</td>\n",
       "      <td>-0.022981</td>\n",
       "      <td>-0.001553</td>\n",
       "      <td>0.110068</td>\n",
       "      <td>0.278629</td>\n",
       "      <td>-0.111650</td>\n",
       "      <td>0.037905</td>\n",
       "      <td>0.078732</td>\n",
       "      <td>0.007991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000547854.jpg</th>\n",
       "      <td>0.095287</td>\n",
       "      <td>0.280398</td>\n",
       "      <td>-0.202505</td>\n",
       "      <td>-0.181303</td>\n",
       "      <td>0.060087</td>\n",
       "      <td>0.028006</td>\n",
       "      <td>0.176680</td>\n",
       "      <td>0.213937</td>\n",
       "      <td>-0.038575</td>\n",
       "      <td>-0.090672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054430</td>\n",
       "      <td>0.202727</td>\n",
       "      <td>-0.029549</td>\n",
       "      <td>0.013683</td>\n",
       "      <td>0.091684</td>\n",
       "      <td>0.255132</td>\n",
       "      <td>-0.151559</td>\n",
       "      <td>0.007893</td>\n",
       "      <td>0.069967</td>\n",
       "      <td>0.025866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000513041.jpg</th>\n",
       "      <td>0.042169</td>\n",
       "      <td>0.229634</td>\n",
       "      <td>-0.160014</td>\n",
       "      <td>-0.207810</td>\n",
       "      <td>0.030657</td>\n",
       "      <td>-0.026603</td>\n",
       "      <td>0.175748</td>\n",
       "      <td>0.250698</td>\n",
       "      <td>0.021657</td>\n",
       "      <td>-0.111831</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003399</td>\n",
       "      <td>0.183725</td>\n",
       "      <td>-0.006009</td>\n",
       "      <td>0.023868</td>\n",
       "      <td>0.128788</td>\n",
       "      <td>0.295200</td>\n",
       "      <td>-0.130164</td>\n",
       "      <td>0.030048</td>\n",
       "      <td>0.101519</td>\n",
       "      <td>0.007504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000146457.jpg</th>\n",
       "      <td>-0.012982</td>\n",
       "      <td>0.297143</td>\n",
       "      <td>-0.136606</td>\n",
       "      <td>-0.208173</td>\n",
       "      <td>0.047192</td>\n",
       "      <td>0.019503</td>\n",
       "      <td>0.098832</td>\n",
       "      <td>0.249749</td>\n",
       "      <td>-0.004266</td>\n",
       "      <td>-0.181809</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040372</td>\n",
       "      <td>0.171669</td>\n",
       "      <td>-0.027924</td>\n",
       "      <td>0.050765</td>\n",
       "      <td>0.109635</td>\n",
       "      <td>0.258975</td>\n",
       "      <td>-0.101933</td>\n",
       "      <td>0.101357</td>\n",
       "      <td>0.076860</td>\n",
       "      <td>-0.021770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000172571.jpg</th>\n",
       "      <td>0.067324</td>\n",
       "      <td>0.295622</td>\n",
       "      <td>-0.194025</td>\n",
       "      <td>-0.226329</td>\n",
       "      <td>0.042870</td>\n",
       "      <td>0.029788</td>\n",
       "      <td>0.207391</td>\n",
       "      <td>0.289758</td>\n",
       "      <td>0.017898</td>\n",
       "      <td>-0.159088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025716</td>\n",
       "      <td>0.213431</td>\n",
       "      <td>-0.058473</td>\n",
       "      <td>0.027627</td>\n",
       "      <td>0.133373</td>\n",
       "      <td>0.342156</td>\n",
       "      <td>-0.136920</td>\n",
       "      <td>0.049493</td>\n",
       "      <td>0.109787</td>\n",
       "      <td>0.004512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000189475.jpg</th>\n",
       "      <td>0.081870</td>\n",
       "      <td>0.222169</td>\n",
       "      <td>-0.175141</td>\n",
       "      <td>-0.146303</td>\n",
       "      <td>0.047162</td>\n",
       "      <td>0.023286</td>\n",
       "      <td>0.117213</td>\n",
       "      <td>0.177639</td>\n",
       "      <td>-0.015449</td>\n",
       "      <td>-0.096310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022870</td>\n",
       "      <td>0.171353</td>\n",
       "      <td>-0.016697</td>\n",
       "      <td>0.012899</td>\n",
       "      <td>0.056562</td>\n",
       "      <td>0.193533</td>\n",
       "      <td>-0.127931</td>\n",
       "      <td>0.007086</td>\n",
       "      <td>0.078189</td>\n",
       "      <td>0.043679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000080932.jpg</th>\n",
       "      <td>0.011675</td>\n",
       "      <td>0.260174</td>\n",
       "      <td>-0.186019</td>\n",
       "      <td>-0.251664</td>\n",
       "      <td>0.013084</td>\n",
       "      <td>-0.010233</td>\n",
       "      <td>0.121742</td>\n",
       "      <td>0.266316</td>\n",
       "      <td>0.046737</td>\n",
       "      <td>-0.182036</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034822</td>\n",
       "      <td>0.192521</td>\n",
       "      <td>-0.050905</td>\n",
       "      <td>0.068705</td>\n",
       "      <td>0.138266</td>\n",
       "      <td>0.278688</td>\n",
       "      <td>-0.141461</td>\n",
       "      <td>0.086186</td>\n",
       "      <td>0.098325</td>\n",
       "      <td>-0.021126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000232489.jpg</th>\n",
       "      <td>0.022350</td>\n",
       "      <td>0.302611</td>\n",
       "      <td>-0.151865</td>\n",
       "      <td>-0.212651</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.041401</td>\n",
       "      <td>0.231518</td>\n",
       "      <td>0.283311</td>\n",
       "      <td>0.036011</td>\n",
       "      <td>-0.158127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078512</td>\n",
       "      <td>0.177989</td>\n",
       "      <td>-0.061241</td>\n",
       "      <td>0.057160</td>\n",
       "      <td>0.159491</td>\n",
       "      <td>0.337397</td>\n",
       "      <td>-0.110104</td>\n",
       "      <td>0.062647</td>\n",
       "      <td>0.081602</td>\n",
       "      <td>-0.009359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000174123.jpg</th>\n",
       "      <td>0.009788</td>\n",
       "      <td>0.328639</td>\n",
       "      <td>-0.170171</td>\n",
       "      <td>-0.255336</td>\n",
       "      <td>0.020957</td>\n",
       "      <td>0.031594</td>\n",
       "      <td>0.189740</td>\n",
       "      <td>0.307619</td>\n",
       "      <td>0.025815</td>\n",
       "      <td>-0.172087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106735</td>\n",
       "      <td>0.190300</td>\n",
       "      <td>-0.088310</td>\n",
       "      <td>0.067207</td>\n",
       "      <td>0.145070</td>\n",
       "      <td>0.316418</td>\n",
       "      <td>-0.157244</td>\n",
       "      <td>0.097336</td>\n",
       "      <td>0.056081</td>\n",
       "      <td>-0.040753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000340015.jpg</th>\n",
       "      <td>-0.002558</td>\n",
       "      <td>0.294009</td>\n",
       "      <td>-0.112496</td>\n",
       "      <td>-0.195602</td>\n",
       "      <td>0.020242</td>\n",
       "      <td>0.030847</td>\n",
       "      <td>0.206300</td>\n",
       "      <td>0.277160</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>-0.139683</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.080070</td>\n",
       "      <td>0.160829</td>\n",
       "      <td>-0.027670</td>\n",
       "      <td>0.030642</td>\n",
       "      <td>0.146454</td>\n",
       "      <td>0.309840</td>\n",
       "      <td>-0.092286</td>\n",
       "      <td>0.077553</td>\n",
       "      <td>0.061859</td>\n",
       "      <td>-0.032745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000027696.jpg</th>\n",
       "      <td>0.040855</td>\n",
       "      <td>0.299723</td>\n",
       "      <td>-0.165851</td>\n",
       "      <td>-0.200695</td>\n",
       "      <td>0.044979</td>\n",
       "      <td>0.037478</td>\n",
       "      <td>0.193248</td>\n",
       "      <td>0.238074</td>\n",
       "      <td>-0.004898</td>\n",
       "      <td>-0.126344</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081710</td>\n",
       "      <td>0.176540</td>\n",
       "      <td>-0.055122</td>\n",
       "      <td>0.046918</td>\n",
       "      <td>0.127298</td>\n",
       "      <td>0.283599</td>\n",
       "      <td>-0.126804</td>\n",
       "      <td>0.043363</td>\n",
       "      <td>0.059886</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000265777.jpg</th>\n",
       "      <td>0.137785</td>\n",
       "      <td>0.263138</td>\n",
       "      <td>-0.240922</td>\n",
       "      <td>-0.097000</td>\n",
       "      <td>0.073902</td>\n",
       "      <td>0.043778</td>\n",
       "      <td>0.164944</td>\n",
       "      <td>0.193758</td>\n",
       "      <td>-0.096923</td>\n",
       "      <td>-0.059559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006700</td>\n",
       "      <td>0.245654</td>\n",
       "      <td>0.028201</td>\n",
       "      <td>-0.037063</td>\n",
       "      <td>0.060367</td>\n",
       "      <td>0.243422</td>\n",
       "      <td>-0.108791</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.108110</td>\n",
       "      <td>0.023346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000357430.jpg</th>\n",
       "      <td>-0.012021</td>\n",
       "      <td>0.236928</td>\n",
       "      <td>-0.118972</td>\n",
       "      <td>-0.230350</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>-0.015423</td>\n",
       "      <td>0.179267</td>\n",
       "      <td>0.257587</td>\n",
       "      <td>0.065139</td>\n",
       "      <td>-0.157796</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033783</td>\n",
       "      <td>0.152781</td>\n",
       "      <td>-0.015193</td>\n",
       "      <td>0.055465</td>\n",
       "      <td>0.170812</td>\n",
       "      <td>0.304208</td>\n",
       "      <td>-0.095600</td>\n",
       "      <td>0.060210</td>\n",
       "      <td>0.097279</td>\n",
       "      <td>-0.011106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000474167.jpg</th>\n",
       "      <td>0.021948</td>\n",
       "      <td>0.220269</td>\n",
       "      <td>-0.149505</td>\n",
       "      <td>-0.238684</td>\n",
       "      <td>0.025425</td>\n",
       "      <td>-0.028458</td>\n",
       "      <td>0.160009</td>\n",
       "      <td>0.229056</td>\n",
       "      <td>0.069227</td>\n",
       "      <td>-0.132046</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030243</td>\n",
       "      <td>0.149193</td>\n",
       "      <td>-0.051920</td>\n",
       "      <td>0.071931</td>\n",
       "      <td>0.134921</td>\n",
       "      <td>0.269779</td>\n",
       "      <td>-0.148810</td>\n",
       "      <td>0.022446</td>\n",
       "      <td>0.081258</td>\n",
       "      <td>0.025582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000113720.jpg</th>\n",
       "      <td>0.048539</td>\n",
       "      <td>0.229346</td>\n",
       "      <td>-0.189714</td>\n",
       "      <td>-0.226851</td>\n",
       "      <td>0.027873</td>\n",
       "      <td>-0.034452</td>\n",
       "      <td>0.155592</td>\n",
       "      <td>0.221841</td>\n",
       "      <td>0.023353</td>\n",
       "      <td>-0.116335</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019120</td>\n",
       "      <td>0.188965</td>\n",
       "      <td>-0.014846</td>\n",
       "      <td>0.045430</td>\n",
       "      <td>0.138380</td>\n",
       "      <td>0.270019</td>\n",
       "      <td>-0.143754</td>\n",
       "      <td>0.021653</td>\n",
       "      <td>0.095992</td>\n",
       "      <td>0.011737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000146489.jpg</th>\n",
       "      <td>-0.022910</td>\n",
       "      <td>0.230615</td>\n",
       "      <td>-0.073401</td>\n",
       "      <td>-0.233950</td>\n",
       "      <td>-0.002525</td>\n",
       "      <td>-0.030862</td>\n",
       "      <td>0.243442</td>\n",
       "      <td>0.340312</td>\n",
       "      <td>0.099536</td>\n",
       "      <td>-0.143064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013335</td>\n",
       "      <td>0.141777</td>\n",
       "      <td>-0.024226</td>\n",
       "      <td>0.042285</td>\n",
       "      <td>0.168231</td>\n",
       "      <td>0.373359</td>\n",
       "      <td>-0.112584</td>\n",
       "      <td>0.061474</td>\n",
       "      <td>0.094286</td>\n",
       "      <td>-0.014322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000429623.jpg</th>\n",
       "      <td>0.027271</td>\n",
       "      <td>0.226635</td>\n",
       "      <td>-0.111029</td>\n",
       "      <td>-0.179555</td>\n",
       "      <td>0.008569</td>\n",
       "      <td>0.020572</td>\n",
       "      <td>0.195851</td>\n",
       "      <td>0.189442</td>\n",
       "      <td>0.034614</td>\n",
       "      <td>-0.088448</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.099945</td>\n",
       "      <td>0.117384</td>\n",
       "      <td>-0.035719</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>0.122622</td>\n",
       "      <td>0.221510</td>\n",
       "      <td>-0.118721</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>0.036234</td>\n",
       "      <td>0.029227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000043581.jpg</th>\n",
       "      <td>0.068350</td>\n",
       "      <td>0.288224</td>\n",
       "      <td>-0.135291</td>\n",
       "      <td>-0.166764</td>\n",
       "      <td>0.041728</td>\n",
       "      <td>0.065725</td>\n",
       "      <td>0.232815</td>\n",
       "      <td>0.236432</td>\n",
       "      <td>-0.016963</td>\n",
       "      <td>-0.110819</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070179</td>\n",
       "      <td>0.170710</td>\n",
       "      <td>-0.030149</td>\n",
       "      <td>-0.003258</td>\n",
       "      <td>0.115124</td>\n",
       "      <td>0.294132</td>\n",
       "      <td>-0.100531</td>\n",
       "      <td>0.014563</td>\n",
       "      <td>0.067425</td>\n",
       "      <td>0.021801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000177213.jpg</th>\n",
       "      <td>0.111140</td>\n",
       "      <td>0.287642</td>\n",
       "      <td>-0.151029</td>\n",
       "      <td>-0.198608</td>\n",
       "      <td>0.079599</td>\n",
       "      <td>0.039001</td>\n",
       "      <td>0.278753</td>\n",
       "      <td>0.251682</td>\n",
       "      <td>-0.006345</td>\n",
       "      <td>-0.080783</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040007</td>\n",
       "      <td>0.176129</td>\n",
       "      <td>-0.051996</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>0.106295</td>\n",
       "      <td>0.333611</td>\n",
       "      <td>-0.158100</td>\n",
       "      <td>-0.045334</td>\n",
       "      <td>0.069506</td>\n",
       "      <td>0.070532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000520264.jpg</th>\n",
       "      <td>0.124583</td>\n",
       "      <td>0.145865</td>\n",
       "      <td>-0.152837</td>\n",
       "      <td>-0.133834</td>\n",
       "      <td>0.058631</td>\n",
       "      <td>-0.013462</td>\n",
       "      <td>0.165710</td>\n",
       "      <td>0.195173</td>\n",
       "      <td>0.038002</td>\n",
       "      <td>-0.067192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078303</td>\n",
       "      <td>0.161681</td>\n",
       "      <td>0.007714</td>\n",
       "      <td>-0.024141</td>\n",
       "      <td>0.043710</td>\n",
       "      <td>0.243334</td>\n",
       "      <td>-0.137815</td>\n",
       "      <td>-0.066337</td>\n",
       "      <td>0.124881</td>\n",
       "      <td>0.114023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000323151.jpg</th>\n",
       "      <td>0.088427</td>\n",
       "      <td>0.265016</td>\n",
       "      <td>-0.174512</td>\n",
       "      <td>-0.162079</td>\n",
       "      <td>0.052793</td>\n",
       "      <td>0.044284</td>\n",
       "      <td>0.248287</td>\n",
       "      <td>0.204760</td>\n",
       "      <td>0.008931</td>\n",
       "      <td>-0.078751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073109</td>\n",
       "      <td>0.167727</td>\n",
       "      <td>-0.058674</td>\n",
       "      <td>0.040046</td>\n",
       "      <td>0.119724</td>\n",
       "      <td>0.284260</td>\n",
       "      <td>-0.129285</td>\n",
       "      <td>-0.025006</td>\n",
       "      <td>0.063972</td>\n",
       "      <td>0.053576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000248400.jpg</th>\n",
       "      <td>-0.015658</td>\n",
       "      <td>0.135887</td>\n",
       "      <td>-0.086458</td>\n",
       "      <td>-0.247211</td>\n",
       "      <td>-0.043712</td>\n",
       "      <td>-0.077089</td>\n",
       "      <td>0.182059</td>\n",
       "      <td>0.133744</td>\n",
       "      <td>0.123521</td>\n",
       "      <td>-0.074705</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093196</td>\n",
       "      <td>0.069663</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.103545</td>\n",
       "      <td>0.189599</td>\n",
       "      <td>0.185227</td>\n",
       "      <td>-0.139452</td>\n",
       "      <td>-0.055533</td>\n",
       "      <td>0.044590</td>\n",
       "      <td>0.070860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000094614.jpg</th>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.049810</td>\n",
       "      <td>-0.171687</td>\n",
       "      <td>-0.113132</td>\n",
       "      <td>0.079786</td>\n",
       "      <td>-0.253182</td>\n",
       "      <td>0.021393</td>\n",
       "      <td>0.113999</td>\n",
       "      <td>0.002422</td>\n",
       "      <td>0.029377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195726</td>\n",
       "      <td>0.183273</td>\n",
       "      <td>0.240541</td>\n",
       "      <td>0.026678</td>\n",
       "      <td>0.072051</td>\n",
       "      <td>0.154455</td>\n",
       "      <td>-0.128628</td>\n",
       "      <td>-0.090079</td>\n",
       "      <td>0.173014</td>\n",
       "      <td>0.114569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000309655.jpg</th>\n",
       "      <td>0.069093</td>\n",
       "      <td>0.105879</td>\n",
       "      <td>-0.157418</td>\n",
       "      <td>-0.091778</td>\n",
       "      <td>0.044386</td>\n",
       "      <td>-0.139637</td>\n",
       "      <td>0.060053</td>\n",
       "      <td>0.101111</td>\n",
       "      <td>-0.058967</td>\n",
       "      <td>0.021038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088859</td>\n",
       "      <td>0.183670</td>\n",
       "      <td>0.223749</td>\n",
       "      <td>-0.037371</td>\n",
       "      <td>0.059743</td>\n",
       "      <td>0.120442</td>\n",
       "      <td>-0.105567</td>\n",
       "      <td>-0.076447</td>\n",
       "      <td>0.129309</td>\n",
       "      <td>0.090003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000005529.jpg</th>\n",
       "      <td>0.006119</td>\n",
       "      <td>0.097759</td>\n",
       "      <td>-0.082594</td>\n",
       "      <td>-0.127088</td>\n",
       "      <td>0.042537</td>\n",
       "      <td>-0.190889</td>\n",
       "      <td>0.043080</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>-0.022917</td>\n",
       "      <td>0.019209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095262</td>\n",
       "      <td>0.140875</td>\n",
       "      <td>0.251922</td>\n",
       "      <td>-0.019102</td>\n",
       "      <td>0.063850</td>\n",
       "      <td>0.112826</td>\n",
       "      <td>-0.121407</td>\n",
       "      <td>-0.080178</td>\n",
       "      <td>0.109909</td>\n",
       "      <td>0.104745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000343453.jpg</th>\n",
       "      <td>0.028346</td>\n",
       "      <td>0.114284</td>\n",
       "      <td>-0.116968</td>\n",
       "      <td>-0.115966</td>\n",
       "      <td>0.041009</td>\n",
       "      <td>-0.156758</td>\n",
       "      <td>0.017398</td>\n",
       "      <td>0.090277</td>\n",
       "      <td>-0.057534</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083252</td>\n",
       "      <td>0.159927</td>\n",
       "      <td>0.261812</td>\n",
       "      <td>-0.034768</td>\n",
       "      <td>0.059060</td>\n",
       "      <td>0.084683</td>\n",
       "      <td>-0.103018</td>\n",
       "      <td>-0.074664</td>\n",
       "      <td>0.116683</td>\n",
       "      <td>0.103357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000470952.jpg</th>\n",
       "      <td>0.034493</td>\n",
       "      <td>0.149669</td>\n",
       "      <td>-0.083395</td>\n",
       "      <td>-0.111675</td>\n",
       "      <td>0.048042</td>\n",
       "      <td>-0.117624</td>\n",
       "      <td>0.068884</td>\n",
       "      <td>0.090344</td>\n",
       "      <td>-0.082670</td>\n",
       "      <td>0.024188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024661</td>\n",
       "      <td>0.137536</td>\n",
       "      <td>0.235016</td>\n",
       "      <td>-0.050222</td>\n",
       "      <td>0.056361</td>\n",
       "      <td>0.088560</td>\n",
       "      <td>-0.108787</td>\n",
       "      <td>-0.090157</td>\n",
       "      <td>0.071390</td>\n",
       "      <td>0.102317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000002473.jpg</th>\n",
       "      <td>-0.007089</td>\n",
       "      <td>0.099317</td>\n",
       "      <td>-0.096655</td>\n",
       "      <td>-0.114928</td>\n",
       "      <td>0.030333</td>\n",
       "      <td>-0.190087</td>\n",
       "      <td>0.044434</td>\n",
       "      <td>0.093869</td>\n",
       "      <td>-0.025386</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040385</td>\n",
       "      <td>0.128761</td>\n",
       "      <td>0.240259</td>\n",
       "      <td>0.019415</td>\n",
       "      <td>0.077630</td>\n",
       "      <td>0.079558</td>\n",
       "      <td>-0.124927</td>\n",
       "      <td>-0.078673</td>\n",
       "      <td>0.080211</td>\n",
       "      <td>0.091716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000099242.jpg</th>\n",
       "      <td>0.023288</td>\n",
       "      <td>0.089540</td>\n",
       "      <td>-0.091471</td>\n",
       "      <td>-0.116057</td>\n",
       "      <td>0.045864</td>\n",
       "      <td>-0.182027</td>\n",
       "      <td>0.038931</td>\n",
       "      <td>0.070570</td>\n",
       "      <td>-0.043276</td>\n",
       "      <td>0.021851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103459</td>\n",
       "      <td>0.140102</td>\n",
       "      <td>0.285678</td>\n",
       "      <td>-0.033008</td>\n",
       "      <td>0.076189</td>\n",
       "      <td>0.093385</td>\n",
       "      <td>-0.095241</td>\n",
       "      <td>-0.112183</td>\n",
       "      <td>0.124347</td>\n",
       "      <td>0.130250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000465836.jpg</th>\n",
       "      <td>-0.013299</td>\n",
       "      <td>0.133410</td>\n",
       "      <td>-0.162382</td>\n",
       "      <td>-0.099702</td>\n",
       "      <td>0.068845</td>\n",
       "      <td>-0.179599</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.132622</td>\n",
       "      <td>-0.034024</td>\n",
       "      <td>-0.055836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155869</td>\n",
       "      <td>0.201906</td>\n",
       "      <td>0.251452</td>\n",
       "      <td>0.026058</td>\n",
       "      <td>0.097471</td>\n",
       "      <td>0.170694</td>\n",
       "      <td>-0.048892</td>\n",
       "      <td>-0.004420</td>\n",
       "      <td>0.185561</td>\n",
       "      <td>0.065182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000542127.jpg</th>\n",
       "      <td>-0.018438</td>\n",
       "      <td>0.123551</td>\n",
       "      <td>-0.094349</td>\n",
       "      <td>-0.133217</td>\n",
       "      <td>0.023246</td>\n",
       "      <td>-0.164489</td>\n",
       "      <td>0.025313</td>\n",
       "      <td>0.147566</td>\n",
       "      <td>-0.006320</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030029</td>\n",
       "      <td>0.134667</td>\n",
       "      <td>0.191068</td>\n",
       "      <td>0.023975</td>\n",
       "      <td>0.053247</td>\n",
       "      <td>0.088901</td>\n",
       "      <td>-0.143603</td>\n",
       "      <td>-0.029744</td>\n",
       "      <td>0.073413</td>\n",
       "      <td>0.065156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000334767.jpg</th>\n",
       "      <td>0.007740</td>\n",
       "      <td>0.067295</td>\n",
       "      <td>-0.186710</td>\n",
       "      <td>-0.100049</td>\n",
       "      <td>0.023842</td>\n",
       "      <td>-0.226273</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.116253</td>\n",
       "      <td>0.011978</td>\n",
       "      <td>0.005448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138329</td>\n",
       "      <td>0.196243</td>\n",
       "      <td>0.271490</td>\n",
       "      <td>0.044206</td>\n",
       "      <td>0.106119</td>\n",
       "      <td>0.137115</td>\n",
       "      <td>-0.093141</td>\n",
       "      <td>-0.055931</td>\n",
       "      <td>0.183531</td>\n",
       "      <td>0.091608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000327605.jpg</th>\n",
       "      <td>0.061257</td>\n",
       "      <td>0.108842</td>\n",
       "      <td>-0.110627</td>\n",
       "      <td>-0.095374</td>\n",
       "      <td>0.045620</td>\n",
       "      <td>-0.124984</td>\n",
       "      <td>0.054683</td>\n",
       "      <td>0.064178</td>\n",
       "      <td>-0.072100</td>\n",
       "      <td>0.029677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060105</td>\n",
       "      <td>0.146560</td>\n",
       "      <td>0.237233</td>\n",
       "      <td>-0.052241</td>\n",
       "      <td>0.050026</td>\n",
       "      <td>0.079513</td>\n",
       "      <td>-0.100787</td>\n",
       "      <td>-0.105841</td>\n",
       "      <td>0.095407</td>\n",
       "      <td>0.114321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000249786.jpg</th>\n",
       "      <td>-0.004963</td>\n",
       "      <td>0.111786</td>\n",
       "      <td>-0.078310</td>\n",
       "      <td>-0.104147</td>\n",
       "      <td>0.052260</td>\n",
       "      <td>-0.172837</td>\n",
       "      <td>0.059357</td>\n",
       "      <td>0.142081</td>\n",
       "      <td>-0.013259</td>\n",
       "      <td>0.027121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069223</td>\n",
       "      <td>0.125449</td>\n",
       "      <td>0.196960</td>\n",
       "      <td>0.011699</td>\n",
       "      <td>0.051245</td>\n",
       "      <td>0.122823</td>\n",
       "      <td>-0.125249</td>\n",
       "      <td>-0.059573</td>\n",
       "      <td>0.082460</td>\n",
       "      <td>0.084779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000528314.jpg</th>\n",
       "      <td>-0.014733</td>\n",
       "      <td>0.120602</td>\n",
       "      <td>-0.058994</td>\n",
       "      <td>-0.115545</td>\n",
       "      <td>0.026172</td>\n",
       "      <td>-0.141253</td>\n",
       "      <td>0.024664</td>\n",
       "      <td>0.128173</td>\n",
       "      <td>-0.024651</td>\n",
       "      <td>-0.007358</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046043</td>\n",
       "      <td>0.118694</td>\n",
       "      <td>0.211406</td>\n",
       "      <td>-0.012707</td>\n",
       "      <td>0.048874</td>\n",
       "      <td>0.086671</td>\n",
       "      <td>-0.106021</td>\n",
       "      <td>-0.036914</td>\n",
       "      <td>0.078215</td>\n",
       "      <td>0.071599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000567740.jpg</th>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.099173</td>\n",
       "      <td>-0.092192</td>\n",
       "      <td>-0.131287</td>\n",
       "      <td>0.026876</td>\n",
       "      <td>-0.161836</td>\n",
       "      <td>0.042641</td>\n",
       "      <td>0.110482</td>\n",
       "      <td>-0.019175</td>\n",
       "      <td>0.007750</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065104</td>\n",
       "      <td>0.135225</td>\n",
       "      <td>0.216654</td>\n",
       "      <td>-0.013104</td>\n",
       "      <td>0.067659</td>\n",
       "      <td>0.101725</td>\n",
       "      <td>-0.118592</td>\n",
       "      <td>-0.068933</td>\n",
       "      <td>0.096641</td>\n",
       "      <td>0.088747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000361919.jpg</th>\n",
       "      <td>-0.004922</td>\n",
       "      <td>0.085696</td>\n",
       "      <td>-0.129736</td>\n",
       "      <td>-0.137026</td>\n",
       "      <td>0.022309</td>\n",
       "      <td>-0.201737</td>\n",
       "      <td>0.037189</td>\n",
       "      <td>0.118135</td>\n",
       "      <td>0.005640</td>\n",
       "      <td>-0.028359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129241</td>\n",
       "      <td>0.169216</td>\n",
       "      <td>0.266768</td>\n",
       "      <td>0.008994</td>\n",
       "      <td>0.118328</td>\n",
       "      <td>0.150397</td>\n",
       "      <td>-0.077437</td>\n",
       "      <td>-0.054872</td>\n",
       "      <td>0.166825</td>\n",
       "      <td>0.088207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000216516.jpg</th>\n",
       "      <td>0.043724</td>\n",
       "      <td>0.096797</td>\n",
       "      <td>-0.138262</td>\n",
       "      <td>-0.093992</td>\n",
       "      <td>0.071541</td>\n",
       "      <td>-0.174965</td>\n",
       "      <td>0.029141</td>\n",
       "      <td>0.113429</td>\n",
       "      <td>-0.041892</td>\n",
       "      <td>0.011291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140982</td>\n",
       "      <td>0.174321</td>\n",
       "      <td>0.236814</td>\n",
       "      <td>-0.022410</td>\n",
       "      <td>0.046996</td>\n",
       "      <td>0.131870</td>\n",
       "      <td>-0.104587</td>\n",
       "      <td>-0.074954</td>\n",
       "      <td>0.144901</td>\n",
       "      <td>0.109388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000142790.jpg</th>\n",
       "      <td>-0.061908</td>\n",
       "      <td>0.099460</td>\n",
       "      <td>-0.039651</td>\n",
       "      <td>-0.126732</td>\n",
       "      <td>0.022093</td>\n",
       "      <td>-0.158151</td>\n",
       "      <td>0.035098</td>\n",
       "      <td>0.147584</td>\n",
       "      <td>0.039222</td>\n",
       "      <td>-0.031374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056366</td>\n",
       "      <td>0.089265</td>\n",
       "      <td>0.158379</td>\n",
       "      <td>0.046758</td>\n",
       "      <td>0.079668</td>\n",
       "      <td>0.125099</td>\n",
       "      <td>-0.091219</td>\n",
       "      <td>-0.012214</td>\n",
       "      <td>0.082266</td>\n",
       "      <td>0.058143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000243148.jpg</th>\n",
       "      <td>-0.026135</td>\n",
       "      <td>0.164105</td>\n",
       "      <td>-0.045790</td>\n",
       "      <td>-0.122132</td>\n",
       "      <td>0.061232</td>\n",
       "      <td>-0.101647</td>\n",
       "      <td>0.051603</td>\n",
       "      <td>0.103171</td>\n",
       "      <td>-0.048151</td>\n",
       "      <td>-0.032286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029642</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.174775</td>\n",
       "      <td>-0.001729</td>\n",
       "      <td>0.078364</td>\n",
       "      <td>0.120818</td>\n",
       "      <td>-0.069315</td>\n",
       "      <td>-0.034909</td>\n",
       "      <td>0.066485</td>\n",
       "      <td>0.068449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000064462.jpg</th>\n",
       "      <td>0.036002</td>\n",
       "      <td>0.165236</td>\n",
       "      <td>-0.115719</td>\n",
       "      <td>-0.111125</td>\n",
       "      <td>0.054053</td>\n",
       "      <td>-0.129784</td>\n",
       "      <td>0.068864</td>\n",
       "      <td>0.110327</td>\n",
       "      <td>-0.095135</td>\n",
       "      <td>0.016241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046375</td>\n",
       "      <td>0.172027</td>\n",
       "      <td>0.256748</td>\n",
       "      <td>-0.049785</td>\n",
       "      <td>0.070625</td>\n",
       "      <td>0.120559</td>\n",
       "      <td>-0.102085</td>\n",
       "      <td>-0.073790</td>\n",
       "      <td>0.099574</td>\n",
       "      <td>0.086766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000407002.jpg</th>\n",
       "      <td>0.011922</td>\n",
       "      <td>0.124751</td>\n",
       "      <td>-0.108452</td>\n",
       "      <td>-0.120336</td>\n",
       "      <td>0.051849</td>\n",
       "      <td>-0.169574</td>\n",
       "      <td>0.051786</td>\n",
       "      <td>0.110132</td>\n",
       "      <td>-0.048432</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091125</td>\n",
       "      <td>0.159417</td>\n",
       "      <td>0.254917</td>\n",
       "      <td>-0.017431</td>\n",
       "      <td>0.087651</td>\n",
       "      <td>0.133869</td>\n",
       "      <td>-0.090649</td>\n",
       "      <td>-0.069347</td>\n",
       "      <td>0.123110</td>\n",
       "      <td>0.090367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000414170.jpg</th>\n",
       "      <td>-0.037123</td>\n",
       "      <td>0.090114</td>\n",
       "      <td>-0.149743</td>\n",
       "      <td>-0.130079</td>\n",
       "      <td>0.045949</td>\n",
       "      <td>-0.223556</td>\n",
       "      <td>-0.014110</td>\n",
       "      <td>0.126710</td>\n",
       "      <td>0.020528</td>\n",
       "      <td>-0.041609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143005</td>\n",
       "      <td>0.170851</td>\n",
       "      <td>0.228004</td>\n",
       "      <td>0.066130</td>\n",
       "      <td>0.103498</td>\n",
       "      <td>0.141707</td>\n",
       "      <td>-0.089003</td>\n",
       "      <td>-0.014938</td>\n",
       "      <td>0.164933</td>\n",
       "      <td>0.070071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000032735.jpg</th>\n",
       "      <td>0.032370</td>\n",
       "      <td>0.094152</td>\n",
       "      <td>-0.113225</td>\n",
       "      <td>-0.080849</td>\n",
       "      <td>0.047351</td>\n",
       "      <td>-0.161957</td>\n",
       "      <td>0.062564</td>\n",
       "      <td>0.153485</td>\n",
       "      <td>-0.016093</td>\n",
       "      <td>0.049950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073444</td>\n",
       "      <td>0.146810</td>\n",
       "      <td>0.180991</td>\n",
       "      <td>-0.002594</td>\n",
       "      <td>0.022337</td>\n",
       "      <td>0.115541</td>\n",
       "      <td>-0.147913</td>\n",
       "      <td>-0.060217</td>\n",
       "      <td>0.086953</td>\n",
       "      <td>0.081142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000002532.jpg</th>\n",
       "      <td>-0.010748</td>\n",
       "      <td>0.100882</td>\n",
       "      <td>-0.073718</td>\n",
       "      <td>-0.138789</td>\n",
       "      <td>0.016227</td>\n",
       "      <td>-0.162286</td>\n",
       "      <td>0.019615</td>\n",
       "      <td>0.093768</td>\n",
       "      <td>-0.017670</td>\n",
       "      <td>-0.021092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070793</td>\n",
       "      <td>0.128527</td>\n",
       "      <td>0.253279</td>\n",
       "      <td>-0.014874</td>\n",
       "      <td>0.085388</td>\n",
       "      <td>0.089191</td>\n",
       "      <td>-0.085636</td>\n",
       "      <td>-0.062079</td>\n",
       "      <td>0.110920</td>\n",
       "      <td>0.093785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000131556.jpg</th>\n",
       "      <td>0.004899</td>\n",
       "      <td>0.070993</td>\n",
       "      <td>-0.065685</td>\n",
       "      <td>-0.125079</td>\n",
       "      <td>0.016424</td>\n",
       "      <td>-0.170412</td>\n",
       "      <td>0.057218</td>\n",
       "      <td>0.093767</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.026007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053491</td>\n",
       "      <td>0.104146</td>\n",
       "      <td>0.212114</td>\n",
       "      <td>-0.001128</td>\n",
       "      <td>0.071514</td>\n",
       "      <td>0.087577</td>\n",
       "      <td>-0.118336</td>\n",
       "      <td>-0.090778</td>\n",
       "      <td>0.083488</td>\n",
       "      <td>0.104513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000154087.jpg</th>\n",
       "      <td>0.078663</td>\n",
       "      <td>0.023516</td>\n",
       "      <td>-0.165323</td>\n",
       "      <td>-0.020946</td>\n",
       "      <td>0.047166</td>\n",
       "      <td>-0.173968</td>\n",
       "      <td>0.062401</td>\n",
       "      <td>0.121436</td>\n",
       "      <td>0.018418</td>\n",
       "      <td>0.043022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182334</td>\n",
       "      <td>0.180128</td>\n",
       "      <td>0.228861</td>\n",
       "      <td>-0.009781</td>\n",
       "      <td>0.025375</td>\n",
       "      <td>0.135734</td>\n",
       "      <td>-0.092861</td>\n",
       "      <td>-0.097401</td>\n",
       "      <td>0.183755</td>\n",
       "      <td>0.136665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000447465.jpg</th>\n",
       "      <td>-0.004986</td>\n",
       "      <td>0.094083</td>\n",
       "      <td>-0.085304</td>\n",
       "      <td>-0.147730</td>\n",
       "      <td>0.016652</td>\n",
       "      <td>-0.175069</td>\n",
       "      <td>0.046730</td>\n",
       "      <td>0.127421</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>-0.006684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070382</td>\n",
       "      <td>0.130332</td>\n",
       "      <td>0.217523</td>\n",
       "      <td>-0.002587</td>\n",
       "      <td>0.085136</td>\n",
       "      <td>0.117308</td>\n",
       "      <td>-0.116761</td>\n",
       "      <td>-0.060716</td>\n",
       "      <td>0.105291</td>\n",
       "      <td>0.087235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000161781.jpg</th>\n",
       "      <td>0.043855</td>\n",
       "      <td>0.105989</td>\n",
       "      <td>-0.121022</td>\n",
       "      <td>-0.097509</td>\n",
       "      <td>0.060923</td>\n",
       "      <td>-0.184400</td>\n",
       "      <td>0.086846</td>\n",
       "      <td>0.086594</td>\n",
       "      <td>-0.062503</td>\n",
       "      <td>0.072089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076882</td>\n",
       "      <td>0.156524</td>\n",
       "      <td>0.260507</td>\n",
       "      <td>-0.022315</td>\n",
       "      <td>0.074510</td>\n",
       "      <td>0.118749</td>\n",
       "      <td>-0.120310</td>\n",
       "      <td>-0.117291</td>\n",
       "      <td>0.101549</td>\n",
       "      <td>0.113297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000352760.jpg</th>\n",
       "      <td>0.046117</td>\n",
       "      <td>0.108266</td>\n",
       "      <td>-0.128687</td>\n",
       "      <td>-0.096438</td>\n",
       "      <td>0.059572</td>\n",
       "      <td>-0.181545</td>\n",
       "      <td>0.051178</td>\n",
       "      <td>0.129553</td>\n",
       "      <td>-0.048361</td>\n",
       "      <td>0.070326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066790</td>\n",
       "      <td>0.160873</td>\n",
       "      <td>0.221699</td>\n",
       "      <td>-0.011068</td>\n",
       "      <td>0.020145</td>\n",
       "      <td>0.087764</td>\n",
       "      <td>-0.172402</td>\n",
       "      <td>-0.090267</td>\n",
       "      <td>0.083933</td>\n",
       "      <td>0.105500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000515577.jpg</th>\n",
       "      <td>-0.001876</td>\n",
       "      <td>0.074457</td>\n",
       "      <td>-0.103652</td>\n",
       "      <td>-0.129324</td>\n",
       "      <td>0.023505</td>\n",
       "      <td>-0.210616</td>\n",
       "      <td>0.035388</td>\n",
       "      <td>0.116455</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.016091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103425</td>\n",
       "      <td>0.146230</td>\n",
       "      <td>0.261620</td>\n",
       "      <td>0.003379</td>\n",
       "      <td>0.082585</td>\n",
       "      <td>0.111834</td>\n",
       "      <td>-0.115562</td>\n",
       "      <td>-0.075534</td>\n",
       "      <td>0.126802</td>\n",
       "      <td>0.101301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000000301563.jpg</th>\n",
       "      <td>0.004939</td>\n",
       "      <td>0.079082</td>\n",
       "      <td>-0.109229</td>\n",
       "      <td>-0.112474</td>\n",
       "      <td>0.032859</td>\n",
       "      <td>-0.199514</td>\n",
       "      <td>0.074467</td>\n",
       "      <td>0.098076</td>\n",
       "      <td>-0.013881</td>\n",
       "      <td>0.028498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099806</td>\n",
       "      <td>0.147491</td>\n",
       "      <td>0.260324</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>0.112978</td>\n",
       "      <td>0.141208</td>\n",
       "      <td>-0.084908</td>\n",
       "      <td>-0.086106</td>\n",
       "      <td>0.132484</td>\n",
       "      <td>0.094051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1503 rows  400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0         1         2         3         4         5    \\\n",
       "000000491008.jpg  0.034389  0.178236 -0.140821 -0.139339 -0.007118  0.009060   \n",
       "000000402433.jpg  0.050274  0.239730 -0.137886 -0.177502  0.029812  0.014745   \n",
       "000000025603.jpg  0.076880  0.263636 -0.209163 -0.225548  0.027096  0.004112   \n",
       "000000385029.jpg  0.103426  0.329491 -0.191061 -0.191092  0.068800  0.075802   \n",
       "000000047112.jpg  0.065815  0.267185 -0.167811 -0.186340  0.025744  0.055847   \n",
       "000000260105.jpg  0.070640  0.271789 -0.176954 -0.127800  0.061398  0.059655   \n",
       "000000306700.jpg  0.062630  0.252479 -0.158598 -0.164164  0.002451  0.059722   \n",
       "000000179214.jpg  0.010683  0.294232 -0.097603 -0.178310  0.006925  0.075486   \n",
       "000000357903.jpg  0.059414  0.275268 -0.149608 -0.186980  0.034771  0.046625   \n",
       "000000547854.jpg  0.095287  0.280398 -0.202505 -0.181303  0.060087  0.028006   \n",
       "000000513041.jpg  0.042169  0.229634 -0.160014 -0.207810  0.030657 -0.026603   \n",
       "000000146457.jpg -0.012982  0.297143 -0.136606 -0.208173  0.047192  0.019503   \n",
       "000000172571.jpg  0.067324  0.295622 -0.194025 -0.226329  0.042870  0.029788   \n",
       "000000189475.jpg  0.081870  0.222169 -0.175141 -0.146303  0.047162  0.023286   \n",
       "000000080932.jpg  0.011675  0.260174 -0.186019 -0.251664  0.013084 -0.010233   \n",
       "000000232489.jpg  0.022350  0.302611 -0.151865 -0.212651  0.023048  0.041401   \n",
       "000000174123.jpg  0.009788  0.328639 -0.170171 -0.255336  0.020957  0.031594   \n",
       "000000340015.jpg -0.002558  0.294009 -0.112496 -0.195602  0.020242  0.030847   \n",
       "000000027696.jpg  0.040855  0.299723 -0.165851 -0.200695  0.044979  0.037478   \n",
       "000000265777.jpg  0.137785  0.263138 -0.240922 -0.097000  0.073902  0.043778   \n",
       "000000357430.jpg -0.012021  0.236928 -0.118972 -0.230350  0.000338 -0.015423   \n",
       "000000474167.jpg  0.021948  0.220269 -0.149505 -0.238684  0.025425 -0.028458   \n",
       "000000113720.jpg  0.048539  0.229346 -0.189714 -0.226851  0.027873 -0.034452   \n",
       "000000146489.jpg -0.022910  0.230615 -0.073401 -0.233950 -0.002525 -0.030862   \n",
       "000000429623.jpg  0.027271  0.226635 -0.111029 -0.179555  0.008569  0.020572   \n",
       "000000043581.jpg  0.068350  0.288224 -0.135291 -0.166764  0.041728  0.065725   \n",
       "000000177213.jpg  0.111140  0.287642 -0.151029 -0.198608  0.079599  0.039001   \n",
       "000000520264.jpg  0.124583  0.145865 -0.152837 -0.133834  0.058631 -0.013462   \n",
       "000000323151.jpg  0.088427  0.265016 -0.174512 -0.162079  0.052793  0.044284   \n",
       "000000248400.jpg -0.015658  0.135887 -0.086458 -0.247211 -0.043712 -0.077089   \n",
       "...                    ...       ...       ...       ...       ...       ...   \n",
       "000000094614.jpg  0.032600  0.049810 -0.171687 -0.113132  0.079786 -0.253182   \n",
       "000000309655.jpg  0.069093  0.105879 -0.157418 -0.091778  0.044386 -0.139637   \n",
       "000000005529.jpg  0.006119  0.097759 -0.082594 -0.127088  0.042537 -0.190889   \n",
       "000000343453.jpg  0.028346  0.114284 -0.116968 -0.115966  0.041009 -0.156758   \n",
       "000000470952.jpg  0.034493  0.149669 -0.083395 -0.111675  0.048042 -0.117624   \n",
       "000000002473.jpg -0.007089  0.099317 -0.096655 -0.114928  0.030333 -0.190087   \n",
       "000000099242.jpg  0.023288  0.089540 -0.091471 -0.116057  0.045864 -0.182027   \n",
       "000000465836.jpg -0.013299  0.133410 -0.162382 -0.099702  0.068845 -0.179599   \n",
       "000000542127.jpg -0.018438  0.123551 -0.094349 -0.133217  0.023246 -0.164489   \n",
       "000000334767.jpg  0.007740  0.067295 -0.186710 -0.100049  0.023842 -0.226273   \n",
       "000000327605.jpg  0.061257  0.108842 -0.110627 -0.095374  0.045620 -0.124984   \n",
       "000000249786.jpg -0.004963  0.111786 -0.078310 -0.104147  0.052260 -0.172837   \n",
       "000000528314.jpg -0.014733  0.120602 -0.058994 -0.115545  0.026172 -0.141253   \n",
       "000000567740.jpg  0.013956  0.099173 -0.092192 -0.131287  0.026876 -0.161836   \n",
       "000000361919.jpg -0.004922  0.085696 -0.129736 -0.137026  0.022309 -0.201737   \n",
       "000000216516.jpg  0.043724  0.096797 -0.138262 -0.093992  0.071541 -0.174965   \n",
       "000000142790.jpg -0.061908  0.099460 -0.039651 -0.126732  0.022093 -0.158151   \n",
       "000000243148.jpg -0.026135  0.164105 -0.045790 -0.122132  0.061232 -0.101647   \n",
       "000000064462.jpg  0.036002  0.165236 -0.115719 -0.111125  0.054053 -0.129784   \n",
       "000000407002.jpg  0.011922  0.124751 -0.108452 -0.120336  0.051849 -0.169574   \n",
       "000000414170.jpg -0.037123  0.090114 -0.149743 -0.130079  0.045949 -0.223556   \n",
       "000000032735.jpg  0.032370  0.094152 -0.113225 -0.080849  0.047351 -0.161957   \n",
       "000000002532.jpg -0.010748  0.100882 -0.073718 -0.138789  0.016227 -0.162286   \n",
       "000000131556.jpg  0.004899  0.070993 -0.065685 -0.125079  0.016424 -0.170412   \n",
       "000000154087.jpg  0.078663  0.023516 -0.165323 -0.020946  0.047166 -0.173968   \n",
       "000000447465.jpg -0.004986  0.094083 -0.085304 -0.147730  0.016652 -0.175069   \n",
       "000000161781.jpg  0.043855  0.105989 -0.121022 -0.097509  0.060923 -0.184400   \n",
       "000000352760.jpg  0.046117  0.108266 -0.128687 -0.096438  0.059572 -0.181545   \n",
       "000000515577.jpg -0.001876  0.074457 -0.103652 -0.129324  0.023505 -0.210616   \n",
       "000000301563.jpg  0.004939  0.079082 -0.109229 -0.112474  0.032859 -0.199514   \n",
       "\n",
       "                       6         7         8         9      ...          390  \\\n",
       "000000491008.jpg  0.084266  0.178405  0.029304 -0.112014    ...    -0.037619   \n",
       "000000402433.jpg  0.190489  0.213520  0.013288 -0.068929    ...    -0.095179   \n",
       "000000025603.jpg  0.126819  0.202667 -0.033685 -0.123941    ...    -0.048814   \n",
       "000000385029.jpg  0.184458  0.273794 -0.064881 -0.129843    ...    -0.052673   \n",
       "000000047112.jpg  0.170204  0.212838 -0.000622 -0.154392    ...    -0.042465   \n",
       "000000260105.jpg  0.163175  0.186536 -0.035283 -0.095375    ...    -0.068267   \n",
       "000000306700.jpg  0.128489  0.233139 -0.014195 -0.137898    ...    -0.061862   \n",
       "000000179214.jpg  0.210692  0.236762  0.000643 -0.151978    ...    -0.100968   \n",
       "000000357903.jpg  0.184829  0.241018 -0.012966 -0.131161    ...    -0.051078   \n",
       "000000547854.jpg  0.176680  0.213937 -0.038575 -0.090672    ...    -0.054430   \n",
       "000000513041.jpg  0.175748  0.250698  0.021657 -0.111831    ...    -0.003399   \n",
       "000000146457.jpg  0.098832  0.249749 -0.004266 -0.181809    ...    -0.040372   \n",
       "000000172571.jpg  0.207391  0.289758  0.017898 -0.159088    ...    -0.025716   \n",
       "000000189475.jpg  0.117213  0.177639 -0.015449 -0.096310    ...    -0.022870   \n",
       "000000080932.jpg  0.121742  0.266316  0.046737 -0.182036    ...    -0.034822   \n",
       "000000232489.jpg  0.231518  0.283311  0.036011 -0.158127    ...    -0.078512   \n",
       "000000174123.jpg  0.189740  0.307619  0.025815 -0.172087    ...    -0.106735   \n",
       "000000340015.jpg  0.206300  0.277160  0.005980 -0.139683    ...    -0.080070   \n",
       "000000027696.jpg  0.193248  0.238074 -0.004898 -0.126344    ...    -0.081710   \n",
       "000000265777.jpg  0.164944  0.193758 -0.096923 -0.059559    ...    -0.006700   \n",
       "000000357430.jpg  0.179267  0.257587  0.065139 -0.157796    ...    -0.033783   \n",
       "000000474167.jpg  0.160009  0.229056  0.069227 -0.132046    ...    -0.030243   \n",
       "000000113720.jpg  0.155592  0.221841  0.023353 -0.116335    ...    -0.019120   \n",
       "000000146489.jpg  0.243442  0.340312  0.099536 -0.143064    ...    -0.013335   \n",
       "000000429623.jpg  0.195851  0.189442  0.034614 -0.088448    ...    -0.099945   \n",
       "000000043581.jpg  0.232815  0.236432 -0.016963 -0.110819    ...    -0.070179   \n",
       "000000177213.jpg  0.278753  0.251682 -0.006345 -0.080783    ...    -0.040007   \n",
       "000000520264.jpg  0.165710  0.195173  0.038002 -0.067192    ...     0.078303   \n",
       "000000323151.jpg  0.248287  0.204760  0.008931 -0.078751    ...    -0.073109   \n",
       "000000248400.jpg  0.182059  0.133744  0.123521 -0.074705    ...    -0.093196   \n",
       "...                    ...       ...       ...       ...    ...          ...   \n",
       "000000094614.jpg  0.021393  0.113999  0.002422  0.029377    ...     0.195726   \n",
       "000000309655.jpg  0.060053  0.101111 -0.058967  0.021038    ...     0.088859   \n",
       "000000005529.jpg  0.043080  0.124200 -0.022917  0.019209    ...     0.095262   \n",
       "000000343453.jpg  0.017398  0.090277 -0.057534  0.003348    ...     0.083252   \n",
       "000000470952.jpg  0.068884  0.090344 -0.082670  0.024188    ...     0.024661   \n",
       "000000002473.jpg  0.044434  0.093869 -0.025386  0.042300    ...     0.040385   \n",
       "000000099242.jpg  0.038931  0.070570 -0.043276  0.021851    ...     0.103459   \n",
       "000000465836.jpg  0.000342  0.132622 -0.034024 -0.055836    ...     0.155869   \n",
       "000000542127.jpg  0.025313  0.147566 -0.006320  0.001663    ...     0.030029   \n",
       "000000334767.jpg  0.025667  0.116253  0.011978  0.005448    ...     0.138329   \n",
       "000000327605.jpg  0.054683  0.064178 -0.072100  0.029677    ...     0.060105   \n",
       "000000249786.jpg  0.059357  0.142081 -0.013259  0.027121    ...     0.069223   \n",
       "000000528314.jpg  0.024664  0.128173 -0.024651 -0.007358    ...     0.046043   \n",
       "000000567740.jpg  0.042641  0.110482 -0.019175  0.007750    ...     0.065104   \n",
       "000000361919.jpg  0.037189  0.118135  0.005640 -0.028359    ...     0.129241   \n",
       "000000216516.jpg  0.029141  0.113429 -0.041892  0.011291    ...     0.140982   \n",
       "000000142790.jpg  0.035098  0.147584  0.039222 -0.031374    ...     0.056366   \n",
       "000000243148.jpg  0.051603  0.103171 -0.048151 -0.032286    ...     0.029642   \n",
       "000000064462.jpg  0.068864  0.110327 -0.095135  0.016241    ...     0.046375   \n",
       "000000407002.jpg  0.051786  0.110132 -0.048432  0.005099    ...     0.091125   \n",
       "000000414170.jpg -0.014110  0.126710  0.020528 -0.041609    ...     0.143005   \n",
       "000000032735.jpg  0.062564  0.153485 -0.016093  0.049950    ...     0.073444   \n",
       "000000002532.jpg  0.019615  0.093768 -0.017670 -0.021092    ...     0.070793   \n",
       "000000131556.jpg  0.057218  0.093767  0.005901  0.026007    ...     0.053491   \n",
       "000000154087.jpg  0.062401  0.121436  0.018418  0.043022    ...     0.182334   \n",
       "000000447465.jpg  0.046730  0.127421  0.005828 -0.006684    ...     0.070382   \n",
       "000000161781.jpg  0.086846  0.086594 -0.062503  0.072089    ...     0.076882   \n",
       "000000352760.jpg  0.051178  0.129553 -0.048361  0.070326    ...     0.066790   \n",
       "000000515577.jpg  0.035388  0.116455  0.001198  0.016091    ...     0.103425   \n",
       "000000301563.jpg  0.074467  0.098076 -0.013881  0.028498    ...     0.099806   \n",
       "\n",
       "                       391       392       393       394       395       396  \\\n",
       "000000491008.jpg  0.144960  0.006647  0.028955  0.068747  0.155727 -0.104296   \n",
       "000000402433.jpg  0.139093 -0.062520  0.044480  0.094899  0.228152 -0.154771   \n",
       "000000025603.jpg  0.210300  0.001907  0.005091  0.111140  0.227810 -0.149922   \n",
       "000000385029.jpg  0.223536 -0.047499 -0.030998  0.069966  0.292518 -0.148160   \n",
       "000000047112.jpg  0.184114 -0.017194  0.006004  0.118310  0.265148 -0.092132   \n",
       "000000260105.jpg  0.175517 -0.041580  0.031629  0.077302  0.223357 -0.107575   \n",
       "000000306700.jpg  0.183026 -0.015303 -0.015338  0.072456  0.215402 -0.110546   \n",
       "000000179214.jpg  0.146854 -0.013425  0.010945  0.145002  0.277677 -0.060167   \n",
       "000000357903.jpg  0.180507 -0.022981 -0.001553  0.110068  0.278629 -0.111650   \n",
       "000000547854.jpg  0.202727 -0.029549  0.013683  0.091684  0.255132 -0.151559   \n",
       "000000513041.jpg  0.183725 -0.006009  0.023868  0.128788  0.295200 -0.130164   \n",
       "000000146457.jpg  0.171669 -0.027924  0.050765  0.109635  0.258975 -0.101933   \n",
       "000000172571.jpg  0.213431 -0.058473  0.027627  0.133373  0.342156 -0.136920   \n",
       "000000189475.jpg  0.171353 -0.016697  0.012899  0.056562  0.193533 -0.127931   \n",
       "000000080932.jpg  0.192521 -0.050905  0.068705  0.138266  0.278688 -0.141461   \n",
       "000000232489.jpg  0.177989 -0.061241  0.057160  0.159491  0.337397 -0.110104   \n",
       "000000174123.jpg  0.190300 -0.088310  0.067207  0.145070  0.316418 -0.157244   \n",
       "000000340015.jpg  0.160829 -0.027670  0.030642  0.146454  0.309840 -0.092286   \n",
       "000000027696.jpg  0.176540 -0.055122  0.046918  0.127298  0.283599 -0.126804   \n",
       "000000265777.jpg  0.245654  0.028201 -0.037063  0.060367  0.243422 -0.108791   \n",
       "000000357430.jpg  0.152781 -0.015193  0.055465  0.170812  0.304208 -0.095600   \n",
       "000000474167.jpg  0.149193 -0.051920  0.071931  0.134921  0.269779 -0.148810   \n",
       "000000113720.jpg  0.188965 -0.014846  0.045430  0.138380  0.270019 -0.143754   \n",
       "000000146489.jpg  0.141777 -0.024226  0.042285  0.168231  0.373359 -0.112584   \n",
       "000000429623.jpg  0.117384 -0.035719  0.048913  0.122622  0.221510 -0.118721   \n",
       "000000043581.jpg  0.170710 -0.030149 -0.003258  0.115124  0.294132 -0.100531   \n",
       "000000177213.jpg  0.176129 -0.051996 -0.007319  0.106295  0.333611 -0.158100   \n",
       "000000520264.jpg  0.161681  0.007714 -0.024141  0.043710  0.243334 -0.137815   \n",
       "000000323151.jpg  0.167727 -0.058674  0.040046  0.119724  0.284260 -0.129285   \n",
       "000000248400.jpg  0.069663  0.005143  0.103545  0.189599  0.185227 -0.139452   \n",
       "...                    ...       ...       ...       ...       ...       ...   \n",
       "000000094614.jpg  0.183273  0.240541  0.026678  0.072051  0.154455 -0.128628   \n",
       "000000309655.jpg  0.183670  0.223749 -0.037371  0.059743  0.120442 -0.105567   \n",
       "000000005529.jpg  0.140875  0.251922 -0.019102  0.063850  0.112826 -0.121407   \n",
       "000000343453.jpg  0.159927  0.261812 -0.034768  0.059060  0.084683 -0.103018   \n",
       "000000470952.jpg  0.137536  0.235016 -0.050222  0.056361  0.088560 -0.108787   \n",
       "000000002473.jpg  0.128761  0.240259  0.019415  0.077630  0.079558 -0.124927   \n",
       "000000099242.jpg  0.140102  0.285678 -0.033008  0.076189  0.093385 -0.095241   \n",
       "000000465836.jpg  0.201906  0.251452  0.026058  0.097471  0.170694 -0.048892   \n",
       "000000542127.jpg  0.134667  0.191068  0.023975  0.053247  0.088901 -0.143603   \n",
       "000000334767.jpg  0.196243  0.271490  0.044206  0.106119  0.137115 -0.093141   \n",
       "000000327605.jpg  0.146560  0.237233 -0.052241  0.050026  0.079513 -0.100787   \n",
       "000000249786.jpg  0.125449  0.196960  0.011699  0.051245  0.122823 -0.125249   \n",
       "000000528314.jpg  0.118694  0.211406 -0.012707  0.048874  0.086671 -0.106021   \n",
       "000000567740.jpg  0.135225  0.216654 -0.013104  0.067659  0.101725 -0.118592   \n",
       "000000361919.jpg  0.169216  0.266768  0.008994  0.118328  0.150397 -0.077437   \n",
       "000000216516.jpg  0.174321  0.236814 -0.022410  0.046996  0.131870 -0.104587   \n",
       "000000142790.jpg  0.089265  0.158379  0.046758  0.079668  0.125099 -0.091219   \n",
       "000000243148.jpg  0.106431  0.174775 -0.001729  0.078364  0.120818 -0.069315   \n",
       "000000064462.jpg  0.172027  0.256748 -0.049785  0.070625  0.120559 -0.102085   \n",
       "000000407002.jpg  0.159417  0.254917 -0.017431  0.087651  0.133869 -0.090649   \n",
       "000000414170.jpg  0.170851  0.228004  0.066130  0.103498  0.141707 -0.089003   \n",
       "000000032735.jpg  0.146810  0.180991 -0.002594  0.022337  0.115541 -0.147913   \n",
       "000000002532.jpg  0.128527  0.253279 -0.014874  0.085388  0.089191 -0.085636   \n",
       "000000131556.jpg  0.104146  0.212114 -0.001128  0.071514  0.087577 -0.118336   \n",
       "000000154087.jpg  0.180128  0.228861 -0.009781  0.025375  0.135734 -0.092861   \n",
       "000000447465.jpg  0.130332  0.217523 -0.002587  0.085136  0.117308 -0.116761   \n",
       "000000161781.jpg  0.156524  0.260507 -0.022315  0.074510  0.118749 -0.120310   \n",
       "000000352760.jpg  0.160873  0.221699 -0.011068  0.020145  0.087764 -0.172402   \n",
       "000000515577.jpg  0.146230  0.261620  0.003379  0.082585  0.111834 -0.115562   \n",
       "000000301563.jpg  0.147491  0.260324  0.002621  0.112978  0.141208 -0.084908   \n",
       "\n",
       "                       397       398       399  \n",
       "000000491008.jpg  0.038082  0.077400  0.021072  \n",
       "000000402433.jpg  0.008544  0.025904  0.011775  \n",
       "000000025603.jpg  0.027732  0.085534  0.006732  \n",
       "000000385029.jpg  0.048956  0.071829 -0.001645  \n",
       "000000047112.jpg  0.031525  0.103163  0.026644  \n",
       "000000260105.jpg  0.023528  0.060895  0.024663  \n",
       "000000306700.jpg  0.064164  0.077507 -0.007365  \n",
       "000000179214.jpg  0.056858  0.063879 -0.007127  \n",
       "000000357903.jpg  0.037905  0.078732  0.007991  \n",
       "000000547854.jpg  0.007893  0.069967  0.025866  \n",
       "000000513041.jpg  0.030048  0.101519  0.007504  \n",
       "000000146457.jpg  0.101357  0.076860 -0.021770  \n",
       "000000172571.jpg  0.049493  0.109787  0.004512  \n",
       "000000189475.jpg  0.007086  0.078189  0.043679  \n",
       "000000080932.jpg  0.086186  0.098325 -0.021126  \n",
       "000000232489.jpg  0.062647  0.081602 -0.009359  \n",
       "000000174123.jpg  0.097336  0.056081 -0.040753  \n",
       "000000340015.jpg  0.077553  0.061859 -0.032745  \n",
       "000000027696.jpg  0.043363  0.059886  0.000110  \n",
       "000000265777.jpg  0.003887  0.108110  0.023346  \n",
       "000000357430.jpg  0.060210  0.097279 -0.011106  \n",
       "000000474167.jpg  0.022446  0.081258  0.025582  \n",
       "000000113720.jpg  0.021653  0.095992  0.011737  \n",
       "000000146489.jpg  0.061474  0.094286 -0.014322  \n",
       "000000429623.jpg -0.000128  0.036234  0.029227  \n",
       "000000043581.jpg  0.014563  0.067425  0.021801  \n",
       "000000177213.jpg -0.045334  0.069506  0.070532  \n",
       "000000520264.jpg -0.066337  0.124881  0.114023  \n",
       "000000323151.jpg -0.025006  0.063972  0.053576  \n",
       "000000248400.jpg -0.055533  0.044590  0.070860  \n",
       "...                    ...       ...       ...  \n",
       "000000094614.jpg -0.090079  0.173014  0.114569  \n",
       "000000309655.jpg -0.076447  0.129309  0.090003  \n",
       "000000005529.jpg -0.080178  0.109909  0.104745  \n",
       "000000343453.jpg -0.074664  0.116683  0.103357  \n",
       "000000470952.jpg -0.090157  0.071390  0.102317  \n",
       "000000002473.jpg -0.078673  0.080211  0.091716  \n",
       "000000099242.jpg -0.112183  0.124347  0.130250  \n",
       "000000465836.jpg -0.004420  0.185561  0.065182  \n",
       "000000542127.jpg -0.029744  0.073413  0.065156  \n",
       "000000334767.jpg -0.055931  0.183531  0.091608  \n",
       "000000327605.jpg -0.105841  0.095407  0.114321  \n",
       "000000249786.jpg -0.059573  0.082460  0.084779  \n",
       "000000528314.jpg -0.036914  0.078215  0.071599  \n",
       "000000567740.jpg -0.068933  0.096641  0.088747  \n",
       "000000361919.jpg -0.054872  0.166825  0.088207  \n",
       "000000216516.jpg -0.074954  0.144901  0.109388  \n",
       "000000142790.jpg -0.012214  0.082266  0.058143  \n",
       "000000243148.jpg -0.034909  0.066485  0.068449  \n",
       "000000064462.jpg -0.073790  0.099574  0.086766  \n",
       "000000407002.jpg -0.069347  0.123110  0.090367  \n",
       "000000414170.jpg -0.014938  0.164933  0.070071  \n",
       "000000032735.jpg -0.060217  0.086953  0.081142  \n",
       "000000002532.jpg -0.062079  0.110920  0.093785  \n",
       "000000131556.jpg -0.090778  0.083488  0.104513  \n",
       "000000154087.jpg -0.097401  0.183755  0.136665  \n",
       "000000447465.jpg -0.060716  0.105291  0.087235  \n",
       "000000161781.jpg -0.117291  0.101549  0.113297  \n",
       "000000352760.jpg -0.090267  0.083933  0.105500  \n",
       "000000515577.jpg -0.075534  0.126802  0.101301  \n",
       "000000301563.jpg -0.086106  0.132484  0.094051  \n",
       "\n",
       "[1503 rows x 400 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# textual modality\n",
    "import doc2vec_wrapped\n",
    "textual_vectors = doc2vec_wrapped.vectorize_content()\n",
    "textual_vectors = pd.DataFrame.from_items(zip(textual_vectors.index, textual_vectors.values)).transpose()\n",
    "textual_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "      <td>1503.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.355654</td>\n",
       "      <td>0.318166</td>\n",
       "      <td>0.291729</td>\n",
       "      <td>0.352245</td>\n",
       "      <td>0.385825</td>\n",
       "      <td>0.244915</td>\n",
       "      <td>0.237441</td>\n",
       "      <td>0.335135</td>\n",
       "      <td>0.283957</td>\n",
       "      <td>0.327072</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418530</td>\n",
       "      <td>0.426724</td>\n",
       "      <td>0.411744</td>\n",
       "      <td>0.355265</td>\n",
       "      <td>0.420206</td>\n",
       "      <td>0.395320</td>\n",
       "      <td>0.537359</td>\n",
       "      <td>0.373122</td>\n",
       "      <td>0.380587</td>\n",
       "      <td>0.393897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.298311</td>\n",
       "      <td>0.237947</td>\n",
       "      <td>0.253558</td>\n",
       "      <td>0.277936</td>\n",
       "      <td>0.292115</td>\n",
       "      <td>0.200343</td>\n",
       "      <td>0.217335</td>\n",
       "      <td>0.254297</td>\n",
       "      <td>0.214626</td>\n",
       "      <td>0.251209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408742</td>\n",
       "      <td>0.395654</td>\n",
       "      <td>0.357959</td>\n",
       "      <td>0.346029</td>\n",
       "      <td>0.411656</td>\n",
       "      <td>0.365647</td>\n",
       "      <td>0.467650</td>\n",
       "      <td>0.363158</td>\n",
       "      <td>0.361049</td>\n",
       "      <td>0.351719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004756</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.143822</td>\n",
       "      <td>0.139100</td>\n",
       "      <td>0.114142</td>\n",
       "      <td>0.142039</td>\n",
       "      <td>0.181004</td>\n",
       "      <td>0.104038</td>\n",
       "      <td>0.088657</td>\n",
       "      <td>0.138301</td>\n",
       "      <td>0.127651</td>\n",
       "      <td>0.140158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116164</td>\n",
       "      <td>0.134149</td>\n",
       "      <td>0.136428</td>\n",
       "      <td>0.095891</td>\n",
       "      <td>0.129346</td>\n",
       "      <td>0.125362</td>\n",
       "      <td>0.178187</td>\n",
       "      <td>0.099052</td>\n",
       "      <td>0.097790</td>\n",
       "      <td>0.116281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.277273</td>\n",
       "      <td>0.260632</td>\n",
       "      <td>0.220164</td>\n",
       "      <td>0.274736</td>\n",
       "      <td>0.315676</td>\n",
       "      <td>0.196037</td>\n",
       "      <td>0.176022</td>\n",
       "      <td>0.277499</td>\n",
       "      <td>0.226696</td>\n",
       "      <td>0.262550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297742</td>\n",
       "      <td>0.315017</td>\n",
       "      <td>0.315816</td>\n",
       "      <td>0.253461</td>\n",
       "      <td>0.300292</td>\n",
       "      <td>0.298466</td>\n",
       "      <td>0.417716</td>\n",
       "      <td>0.274856</td>\n",
       "      <td>0.265897</td>\n",
       "      <td>0.310238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.478862</td>\n",
       "      <td>0.436851</td>\n",
       "      <td>0.383518</td>\n",
       "      <td>0.496978</td>\n",
       "      <td>0.525515</td>\n",
       "      <td>0.331019</td>\n",
       "      <td>0.314601</td>\n",
       "      <td>0.464446</td>\n",
       "      <td>0.381805</td>\n",
       "      <td>0.451626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602347</td>\n",
       "      <td>0.620506</td>\n",
       "      <td>0.594137</td>\n",
       "      <td>0.514351</td>\n",
       "      <td>0.574434</td>\n",
       "      <td>0.551814</td>\n",
       "      <td>0.773599</td>\n",
       "      <td>0.530467</td>\n",
       "      <td>0.576464</td>\n",
       "      <td>0.575275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.975805</td>\n",
       "      <td>1.489835</td>\n",
       "      <td>1.968467</td>\n",
       "      <td>1.778700</td>\n",
       "      <td>2.346548</td>\n",
       "      <td>1.932409</td>\n",
       "      <td>1.690809</td>\n",
       "      <td>1.751645</td>\n",
       "      <td>1.642197</td>\n",
       "      <td>1.899562</td>\n",
       "      <td>...</td>\n",
       "      <td>2.726681</td>\n",
       "      <td>2.742829</td>\n",
       "      <td>2.146388</td>\n",
       "      <td>2.797326</td>\n",
       "      <td>2.461991</td>\n",
       "      <td>2.727641</td>\n",
       "      <td>2.810951</td>\n",
       "      <td>2.588238</td>\n",
       "      <td>2.122325</td>\n",
       "      <td>2.200421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0            1            2            3            4     \\\n",
       "count  1503.000000  1503.000000  1503.000000  1503.000000  1503.000000   \n",
       "mean      0.355654     0.318166     0.291729     0.352245     0.385825   \n",
       "std       0.298311     0.237947     0.253558     0.277936     0.292115   \n",
       "min       0.000703     0.000000     0.000000     0.000000     0.001554   \n",
       "25%       0.143822     0.139100     0.114142     0.142039     0.181004   \n",
       "50%       0.277273     0.260632     0.220164     0.274736     0.315676   \n",
       "75%       0.478862     0.436851     0.383518     0.496978     0.525515   \n",
       "max       1.975805     1.489835     1.968467     1.778700     2.346548   \n",
       "\n",
       "              5            6            7            8            9     \\\n",
       "count  1503.000000  1503.000000  1503.000000  1503.000000  1503.000000   \n",
       "mean      0.244915     0.237441     0.335135     0.283957     0.327072   \n",
       "std       0.200343     0.217335     0.254297     0.214626     0.251209   \n",
       "min       0.000000     0.000000     0.000000     0.004756     0.003344   \n",
       "25%       0.104038     0.088657     0.138301     0.127651     0.140158   \n",
       "50%       0.196037     0.176022     0.277499     0.226696     0.262550   \n",
       "75%       0.331019     0.314601     0.464446     0.381805     0.451626   \n",
       "max       1.932409     1.690809     1.751645     1.642197     1.899562   \n",
       "\n",
       "          ...              2038         2039         2040         2041  \\\n",
       "count     ...       1503.000000  1503.000000  1503.000000  1503.000000   \n",
       "mean      ...          0.418530     0.426724     0.411744     0.355265   \n",
       "std       ...          0.408742     0.395654     0.357959     0.346029   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.116164     0.134149     0.136428     0.095891   \n",
       "50%       ...          0.297742     0.315017     0.315816     0.253461   \n",
       "75%       ...          0.602347     0.620506     0.594137     0.514351   \n",
       "max       ...          2.726681     2.742829     2.146388     2.797326   \n",
       "\n",
       "              2042         2043         2044         2045         2046  \\\n",
       "count  1503.000000  1503.000000  1503.000000  1503.000000  1503.000000   \n",
       "mean      0.420206     0.395320     0.537359     0.373122     0.380587   \n",
       "std       0.411656     0.365647     0.467650     0.363158     0.361049   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.129346     0.125362     0.178187     0.099052     0.097790   \n",
       "50%       0.300292     0.298466     0.417716     0.274856     0.265897   \n",
       "75%       0.574434     0.551814     0.773599     0.530467     0.576464   \n",
       "max       2.461991     2.727641     2.810951     2.588238     2.122325   \n",
       "\n",
       "              2047  \n",
       "count  1503.000000  \n",
       "mean      0.393897  \n",
       "std       0.351719  \n",
       "min       0.000000  \n",
       "25%       0.116281  \n",
       "50%       0.310238  \n",
       "75%       0.575275  \n",
       "max       2.200421  \n",
       "\n",
       "[8 rows x 2048 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load image modality\n",
    "image_df = pd.read_json(\"data/inception_output.txt\", typ=\"series\", orient=\"records\", lines=True)\n",
    "i = image_df.apply(lambda e: list(e.keys())[0]).values\n",
    "image_vectors = pd.DataFrame.from_items(zip(i, image_df.apply(lambda e: np.array(list(e.values())[0])))).transpose()\n",
    "image_vectors = image_vectors.drop_duplicates()\n",
    "image_vectors.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "side_one_dim = len(image_vectors.iloc[0])\n",
    "side_two_dim = len(textual_vectors.iloc[0])\n",
    "\n",
    "# this is the size of our encoded representations\n",
    "encoding_dim = 100  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(side_one_dim,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(side_two_dim, activation='sigmoid')(encoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is our input placeholder\n",
    "rev_input_text = Input(shape=(side_two_dim,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "rev_encoded = Dense(encoding_dim, activation='sigmoid')(rev_input_text)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "rev_decoded = Dense(side_one_dim, activation='relu')(rev_encoded)\n",
    "\n",
    "rev_autoencoder = Model(rev_input_text, rev_decoded)\n",
    "rev_autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this model maps an input to its encoded representation\n",
    "encoder = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a placeholder for an encoded (32-dimensional) input\n",
    "encoded_input = Input(shape=(side_one_dim,))\n",
    "# retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# create the decoder model\n",
    "decoder = Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['000000149770.jpg', '000000043737.jpg', '000000550797.jpg',\n",
       "       '000000352584.jpg', '000000144798.jpg', '000000355677.jpg',\n",
       "       '000000151051.jpg', '000000244379.jpg', '000000179214.jpg',\n",
       "       '000000084674.jpg',\n",
       "       ...\n",
       "       '000000334417.jpg', '000000285894.jpg', '000000131273.jpg',\n",
       "       '000000567011.jpg', '000000574520.jpg', '000000081766.jpg',\n",
       "       '000000273715.jpg', '000000049810.jpg', '000000273642.jpg',\n",
       "       '000000225670.jpg'],\n",
       "      dtype='object', length=1202)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersecting_idx = textual_vectors.sample(frac=1).index.intersection(image_vectors.index)\n",
    "# train_idx = \n",
    "train_validate_split = 0.8\n",
    "\n",
    "train_idx = intersecting_idx[:int(len(intersecting_idx)*train_validate_split)]\n",
    "test_idx = intersecting_idx[int(len(intersecting_idx)*train_validate_split):]\n",
    "train_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['000000491008.jpg', '000000402433.jpg', '000000025603.jpg',\n",
       "       '000000385029.jpg', '000000047112.jpg', '000000260105.jpg',\n",
       "       '000000306700.jpg', '000000179214.jpg', '000000357903.jpg',\n",
       "       '000000547854.jpg',\n",
       "       ...\n",
       "       '000000414170.jpg', '000000032735.jpg', '000000002532.jpg',\n",
       "       '000000131556.jpg', '000000154087.jpg', '000000447465.jpg',\n",
       "       '000000161781.jpg', '000000352760.jpg', '000000515577.jpg',\n",
       "       '000000301563.jpg'],\n",
       "      dtype='object', length=1503)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textual_vectors.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1202 samples, validate on 301 samples\n",
      "Epoch 1/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4239 - val_loss: -0.4219\n",
      "Epoch 2/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4245 - val_loss: -0.4224\n",
      "Epoch 3/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4249 - val_loss: -0.4230\n",
      "Epoch 4/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4252 - val_loss: -0.4234\n",
      "Epoch 5/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4255 - val_loss: -0.4234\n",
      "Epoch 6/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4258 - val_loss: -0.4239\n",
      "Epoch 7/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4261 - val_loss: -0.4244\n",
      "Epoch 8/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4264 - val_loss: -0.4249\n",
      "Epoch 9/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4267 - val_loss: -0.4251\n",
      "Epoch 10/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4270 - val_loss: -0.4255\n",
      "Epoch 11/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4274 - val_loss: -0.4258\n",
      "Epoch 12/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4276 - val_loss: -0.4260\n",
      "Epoch 13/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4279 - val_loss: -0.4265\n",
      "Epoch 14/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4282 - val_loss: -0.4269\n",
      "Epoch 15/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4285 - val_loss: -0.4272\n",
      "Epoch 16/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4287 - val_loss: -0.4275\n",
      "Epoch 17/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4290 - val_loss: -0.4278\n",
      "Epoch 18/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4292 - val_loss: -0.4280\n",
      "Epoch 19/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4295 - val_loss: -0.4284\n",
      "Epoch 20/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4298 - val_loss: -0.4286\n",
      "Epoch 21/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4300 - val_loss: -0.4289\n",
      "Epoch 22/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4301 - val_loss: -0.4291\n",
      "Epoch 23/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4304 - val_loss: -0.4293\n",
      "Epoch 24/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4306 - val_loss: -0.4296\n",
      "Epoch 25/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4308 - val_loss: -0.4298\n",
      "Epoch 26/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4310 - val_loss: -0.4301\n",
      "Epoch 27/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4312 - val_loss: -0.4303\n",
      "Epoch 28/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4314 - val_loss: -0.4305\n",
      "Epoch 29/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4316 - val_loss: -0.4305\n",
      "Epoch 30/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4318 - val_loss: -0.4307\n",
      "Epoch 31/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4321 - val_loss: -0.4309\n",
      "Epoch 32/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4322 - val_loss: -0.4312\n",
      "Epoch 33/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4325 - val_loss: -0.4316\n",
      "Epoch 34/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4326 - val_loss: -0.4319\n",
      "Epoch 35/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4329 - val_loss: -0.4319\n",
      "Epoch 36/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4331 - val_loss: -0.4323\n",
      "Epoch 37/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4333 - val_loss: -0.4327\n",
      "Epoch 38/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4335 - val_loss: -0.4328\n",
      "Epoch 39/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4338 - val_loss: -0.4331\n",
      "Epoch 40/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4340 - val_loss: -0.4333\n",
      "Epoch 41/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4343 - val_loss: -0.4336\n",
      "Epoch 42/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4345 - val_loss: -0.4338\n",
      "Epoch 43/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4347 - val_loss: -0.4341\n",
      "Epoch 44/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4350 - val_loss: -0.4342\n",
      "Epoch 45/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4352 - val_loss: -0.4346\n",
      "Epoch 46/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4355 - val_loss: -0.4348\n",
      "Epoch 47/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4356 - val_loss: -0.4351\n",
      "Epoch 48/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4359 - val_loss: -0.4352\n",
      "Epoch 49/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4361 - val_loss: -0.4355\n",
      "Epoch 50/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4363 - val_loss: -0.4359\n",
      "Epoch 51/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4365 - val_loss: -0.4361\n",
      "Epoch 52/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4368 - val_loss: -0.4362\n",
      "Epoch 53/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4370 - val_loss: -0.4365\n",
      "Epoch 54/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4372 - val_loss: -0.4368\n",
      "Epoch 55/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4375 - val_loss: -0.4369\n",
      "Epoch 56/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4377 - val_loss: -0.4373\n",
      "Epoch 57/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4379 - val_loss: -0.4376\n",
      "Epoch 58/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4381 - val_loss: -0.4377\n",
      "Epoch 59/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4384 - val_loss: -0.4380\n",
      "Epoch 60/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4386 - val_loss: -0.4381\n",
      "Epoch 61/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4388 - val_loss: -0.4384\n",
      "Epoch 62/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4390 - val_loss: -0.4386\n",
      "Epoch 63/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4392 - val_loss: -0.4388\n",
      "Epoch 64/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4394 - val_loss: -0.4390\n",
      "Epoch 65/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4396 - val_loss: -0.4393\n",
      "Epoch 66/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4399 - val_loss: -0.4394\n",
      "Epoch 67/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4400 - val_loss: -0.4396\n",
      "Epoch 68/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4403 - val_loss: -0.4398\n",
      "Epoch 69/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4405 - val_loss: -0.4401\n",
      "Epoch 70/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4408 - val_loss: -0.4404\n",
      "Epoch 71/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4410 - val_loss: -0.4407\n",
      "Epoch 72/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4412 - val_loss: -0.4408\n",
      "Epoch 73/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4415 - val_loss: -0.4410\n",
      "Epoch 74/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4417 - val_loss: -0.4414\n",
      "Epoch 75/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4419 - val_loss: -0.4416\n",
      "Epoch 76/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4421 - val_loss: -0.4419\n",
      "Epoch 77/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4424 - val_loss: -0.4421\n",
      "Epoch 78/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4427 - val_loss: -0.4424\n",
      "Epoch 79/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4429 - val_loss: -0.4426\n",
      "Epoch 80/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4431 - val_loss: -0.4428\n",
      "Epoch 81/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4434 - val_loss: -0.4432\n",
      "Epoch 82/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4436 - val_loss: -0.4434\n",
      "Epoch 83/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4439 - val_loss: -0.4437\n",
      "Epoch 84/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4441 - val_loss: -0.4440\n",
      "Epoch 85/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4444 - val_loss: -0.4443\n",
      "Epoch 86/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4446 - val_loss: -0.4444\n",
      "Epoch 87/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4448 - val_loss: -0.4447\n",
      "Epoch 88/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4451 - val_loss: -0.4447\n",
      "Epoch 89/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4453 - val_loss: -0.4451\n",
      "Epoch 90/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4455 - val_loss: -0.4454\n",
      "Epoch 91/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4457 - val_loss: -0.4456\n",
      "Epoch 92/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4460 - val_loss: -0.4457\n",
      "Epoch 93/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4462 - val_loss: -0.4458\n",
      "Epoch 94/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4465 - val_loss: -0.4463\n",
      "Epoch 95/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4467 - val_loss: -0.4462\n",
      "Epoch 96/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4469 - val_loss: -0.4467\n",
      "Epoch 97/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4472 - val_loss: -0.4470\n",
      "Epoch 98/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4474 - val_loss: -0.4473\n",
      "Epoch 99/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4477 - val_loss: -0.4475\n",
      "Epoch 100/100\n",
      "1202/1202 [==============================] - 0s - loss: -0.4479 - val_loss: -0.4477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd83d1d80f0>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(image_vectors.loc[train_idx].values, textual_vectors.loc[train_idx].values,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(image_vectors.loc[test_idx].values, textual_vectors.loc[test_idx].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1202 samples, validate on 301 samples\n",
      "Epoch 1/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.6030 - val_loss: 2.5363\n",
      "Epoch 2/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.6015 - val_loss: 2.5361\n",
      "Epoch 3/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.6014 - val_loss: 2.5359\n",
      "Epoch 4/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.6013 - val_loss: 2.5358\n",
      "Epoch 5/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.6012 - val_loss: 2.5357\n",
      "Epoch 6/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.6012 - val_loss: 2.5357\n",
      "Epoch 7/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.6011 - val_loss: 2.5356\n",
      "Epoch 8/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.6011 - val_loss: 2.5356\n",
      "Epoch 9/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.6011 - val_loss: 2.5356\n",
      "Epoch 10/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.6010 - val_loss: 2.5356\n",
      "Epoch 11/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.6010 - val_loss: 2.5355\n",
      "Epoch 12/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.6010 - val_loss: 2.5355\n",
      "Epoch 13/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.6010 - val_loss: 2.5355\n",
      "Epoch 14/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.6010 - val_loss: 2.5336\n",
      "Epoch 15/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5983 - val_loss: 2.5325\n",
      "Epoch 16/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5980 - val_loss: 2.5324\n",
      "Epoch 17/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5979 - val_loss: 2.5324\n",
      "Epoch 18/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5978 - val_loss: 2.5323\n",
      "Epoch 19/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5978 - val_loss: 2.5323\n",
      "Epoch 20/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5978 - val_loss: 2.5322\n",
      "Epoch 21/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5977 - val_loss: 2.5322\n",
      "Epoch 22/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5976 - val_loss: 2.5304\n",
      "Epoch 23/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5960 - val_loss: 2.5303\n",
      "Epoch 24/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5959 - val_loss: 2.5303\n",
      "Epoch 25/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5959 - val_loss: 2.5302\n",
      "Epoch 26/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5959 - val_loss: 2.5302\n",
      "Epoch 27/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5958 - val_loss: 2.5302\n",
      "Epoch 28/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5958 - val_loss: 2.5301\n",
      "Epoch 29/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5958 - val_loss: 2.5301\n",
      "Epoch 30/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5956 - val_loss: 2.5287\n",
      "Epoch 31/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5942 - val_loss: 2.5286\n",
      "Epoch 32/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5941 - val_loss: 2.5286\n",
      "Epoch 33/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5940 - val_loss: 2.5273\n",
      "Epoch 34/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5923 - val_loss: 2.5246\n",
      "Epoch 35/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5900 - val_loss: 2.5245\n",
      "Epoch 36/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5899 - val_loss: 2.5244\n",
      "Epoch 37/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5898 - val_loss: 2.5244\n",
      "Epoch 38/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5897 - val_loss: 2.5243\n",
      "Epoch 39/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5897 - val_loss: 2.5243\n",
      "Epoch 40/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5896 - val_loss: 2.5242\n",
      "Epoch 41/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5896 - val_loss: 2.5242\n",
      "Epoch 42/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5896 - val_loss: 2.5242\n",
      "Epoch 43/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5895 - val_loss: 2.5241\n",
      "Epoch 44/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5895 - val_loss: 2.5241\n",
      "Epoch 45/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5895 - val_loss: 2.5241\n",
      "Epoch 46/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5894 - val_loss: 2.5240\n",
      "Epoch 47/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5894 - val_loss: 2.5240\n",
      "Epoch 48/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5894 - val_loss: 2.5240\n",
      "Epoch 49/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5894 - val_loss: 2.5240\n",
      "Epoch 50/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5893 - val_loss: 2.5239\n",
      "Epoch 51/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5893 - val_loss: 2.5239\n",
      "Epoch 52/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5893 - val_loss: 2.5239\n",
      "Epoch 53/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5893 - val_loss: 2.5239\n",
      "Epoch 54/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5893 - val_loss: 2.5238\n",
      "Epoch 55/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5892 - val_loss: 2.5238\n",
      "Epoch 56/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5892 - val_loss: 2.5238\n",
      "Epoch 57/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5892 - val_loss: 2.5238\n",
      "Epoch 58/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5892 - val_loss: 2.5238\n",
      "Epoch 59/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5892 - val_loss: 2.5238\n",
      "Epoch 60/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5892 - val_loss: 2.5237\n",
      "Epoch 61/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5891 - val_loss: 2.5237\n",
      "Epoch 62/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5891 - val_loss: 2.5237\n",
      "Epoch 63/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5891 - val_loss: 2.5237\n",
      "Epoch 64/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5891 - val_loss: 2.5237\n",
      "Epoch 65/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5885 - val_loss: 2.5222\n",
      "Epoch 66/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5875 - val_loss: 2.5222\n",
      "Epoch 67/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5874 - val_loss: 2.5221\n",
      "Epoch 68/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5874 - val_loss: 2.5221\n",
      "Epoch 69/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5874 - val_loss: 2.5221\n",
      "Epoch 70/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5874 - val_loss: 2.5221\n",
      "Epoch 71/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5874 - val_loss: 2.5221\n",
      "Epoch 72/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5868 - val_loss: 2.5200\n",
      "Epoch 73/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5852 - val_loss: 2.5199\n",
      "Epoch 74/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5851 - val_loss: 2.5199\n",
      "Epoch 75/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5851 - val_loss: 2.5198\n",
      "Epoch 76/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5850 - val_loss: 2.5198\n",
      "Epoch 77/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5850 - val_loss: 2.5198\n",
      "Epoch 78/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5849 - val_loss: 2.5179\n",
      "Epoch 79/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5830 - val_loss: 2.5177\n",
      "Epoch 80/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5829 - val_loss: 2.5177\n",
      "Epoch 81/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5828 - val_loss: 2.5177\n",
      "Epoch 82/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5828 - val_loss: 2.5176\n",
      "Epoch 83/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5828 - val_loss: 2.5176\n",
      "Epoch 84/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5827 - val_loss: 2.5176\n",
      "Epoch 85/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5822 - val_loss: 2.5154\n",
      "Epoch 86/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5805 - val_loss: 2.5152\n",
      "Epoch 87/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5804 - val_loss: 2.5152\n",
      "Epoch 88/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5804 - val_loss: 2.5151\n",
      "Epoch 89/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5803 - val_loss: 2.5151\n",
      "Epoch 90/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5803 - val_loss: 2.5151\n",
      "Epoch 91/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5796 - val_loss: 2.5129\n",
      "Epoch 92/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5782 - val_loss: 2.5128\n",
      "Epoch 93/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5780 - val_loss: 2.5114\n",
      "Epoch 94/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5765 - val_loss: 2.5113\n",
      "Epoch 95/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5764 - val_loss: 2.5113\n",
      "Epoch 96/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5764 - val_loss: 2.5112\n",
      "Epoch 97/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5763 - val_loss: 2.5112\n",
      "Epoch 98/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5762 - val_loss: 2.5085\n",
      "Epoch 99/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5735 - val_loss: 2.5082\n",
      "Epoch 100/100\n",
      "1202/1202 [==============================] - 0s - loss: 2.5733 - val_loss: 2.5081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd83d1b05f8>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_autoencoder.fit(textual_vectors.loc[train_idx].values, image_vectors.loc[train_idx].values,\n",
    "                epochs=100,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(textual_vectors.loc[test_idx].values, image_vectors.loc[test_idx].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def generate_latent_space(forward_autoencoder, backward_autoencoder, forward_data, backward_data):\n",
    "    inp = autoencoder.input\n",
    "\n",
    "    outputs = [layer.output for layer in autoencoder.layers]          # all layer outputs\n",
    "    functor = K.function([inp]+ [K.learning_phase()], outputs ) # evaluation function\n",
    "\n",
    "    # Testing\n",
    "    layer_outs = functor([forward_data, 1.])\n",
    "\n",
    "    compressed_layer_activations = layer_outs[1]\n",
    "    \n",
    "    # reverse activations:\n",
    "    inp = rev_autoencoder.input\n",
    "\n",
    "    outputs = [layer.output for layer in rev_autoencoder.layers]          # all layer outputs\n",
    "    functor = K.function([inp]+ [K.learning_phase()], outputs ) # evaluation function\n",
    "\n",
    "    # Testing\n",
    "    layer_outs = functor([backward_data, 1.])\n",
    "\n",
    "    rev_compressed_layer_activations = layer_outs[1]\n",
    "    \n",
    "    print(\"Forward:\")\n",
    "    print(compressed_layer_activations)\n",
    "    print(\"Backward:\")\n",
    "    print(rev_compressed_layer_activations)\n",
    "    \n",
    "    averaged_activations = np.mean([compressed_layer_activations, rev_compressed_layer_activations], axis=0)\n",
    "    print(\"Averaged:\")\n",
    "    print(averaged_activations)\n",
    "    \n",
    "    return averaged_activations\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward:\n",
      "[[ 11.76197529   7.6168499    3.69601154 ...,  11.36211586  10.33553886\n",
      "    0.        ]\n",
      " [  8.06639671   8.329216     5.43006659 ...,   5.73900223   5.02350855\n",
      "    0.        ]\n",
      " [  4.67551565   4.95196104   2.09629679 ...,  10.04782867   6.86398411\n",
      "    0.        ]\n",
      " ..., \n",
      " [  8.02451611   5.59275103   2.17280221 ...,   7.60000277   7.27087736\n",
      "    0.        ]\n",
      " [  9.53728104   6.62177658   3.33593154 ...,   9.67692852   9.79605865\n",
      "    0.        ]\n",
      " [ 10.67280293   9.08428097   4.98587084 ...,   9.16618443  10.45310688\n",
      "    0.        ]]\n",
      "Backward:\n",
      "[[ 0.47444463  0.59270543  0.50024337 ...,  0.56493646  0.5143277\n",
      "   0.5378831 ]\n",
      " [ 0.54954392  0.51045918  0.51903266 ...,  0.5761438   0.4765085\n",
      "   0.50532711]\n",
      " [ 0.47026566  0.49536839  0.52935225 ...,  0.54529071  0.52171344\n",
      "   0.5459137 ]\n",
      " ..., \n",
      " [ 0.52468485  0.58980387  0.53009474 ...,  0.52014673  0.47743374\n",
      "   0.54378021]\n",
      " [ 0.52520365  0.60593295  0.51890332 ...,  0.53357732  0.50078708\n",
      "   0.52724099]\n",
      " [ 0.54440945  0.62460876  0.5762139  ...,  0.56257933  0.50311363\n",
      "   0.50466198]]\n",
      "Averaged:\n",
      "[[ 6.11820984  4.10477781  2.09812737 ...,  5.96352625  5.42493343\n",
      "   0.26894155]\n",
      " [ 4.30797052  4.41983747  2.97454953 ...,  3.15757298  2.75000858\n",
      "   0.25266355]\n",
      " [ 2.57289076  2.72366476  1.31282449 ...,  5.29655981  3.69284868\n",
      "   0.27295685]\n",
      " ..., \n",
      " [ 4.27460051  3.09127736  1.35144854 ...,  4.06007481  3.87415552\n",
      "   0.2718901 ]\n",
      " [ 5.03124237  3.61385489  1.9274174  ...,  5.10525274  5.14842272\n",
      "   0.2636205 ]\n",
      " [ 5.60860634  4.85444498  2.78104234 ...,  4.86438179  5.47811031\n",
      "   0.25233099]]\n",
      "Forward:\n",
      "[[ 12.31593132  10.08180237   6.58837509 ...,   7.32793331   7.73530102\n",
      "    0.        ]\n",
      " [  5.10871696   4.83306408   2.93337798 ...,   6.78657055   7.28142405\n",
      "    0.        ]\n",
      " [  3.14291692   5.04177666   1.55776191 ...,   4.81639481   8.7087431    0.        ]\n",
      " ..., \n",
      " [  4.51788568   3.9196198    3.33553791 ...,   3.87721515   4.22571182\n",
      "    0.        ]\n",
      " [  5.89922619   4.85341167   2.58851933 ...,   7.95592642   6.94518852\n",
      "    0.        ]\n",
      " [  3.76531219   4.47058487   3.52394271 ...,   3.80061364   5.05695534\n",
      "    0.        ]]\n",
      "Backward:\n",
      "[[ 0.54393685  0.54773498  0.48371896 ...,  0.59082323  0.50084609\n",
      "   0.52123243]\n",
      " [ 0.55869377  0.52676654  0.59468514 ...,  0.51337039  0.5166676\n",
      "   0.58643389]\n",
      " [ 0.49415731  0.54012227  0.62571692 ...,  0.57912827  0.50263518\n",
      "   0.51954913]\n",
      " ..., \n",
      " [ 0.54002941  0.54587966  0.55469435 ...,  0.57809824  0.44429383\n",
      "   0.51025641]\n",
      " [ 0.49183431  0.52313364  0.53756905 ...,  0.56119478  0.52247167\n",
      "   0.50315613]\n",
      " [ 0.51904804  0.52826625  0.60320508 ...,  0.5581947   0.45869517\n",
      "   0.51999766]]\n",
      "Averaged:\n",
      "[[ 6.42993402  5.31476879  3.53604698 ...,  3.95937824  4.11807346\n",
      "   0.26061621]\n",
      " [ 2.83370543  2.67991543  1.76403153 ...,  3.64997053  3.89904594\n",
      "   0.29321694]\n",
      " [ 1.81853712  2.79094934  1.09173942 ...,  2.69776154  4.60568905\n",
      "   0.25977457]\n",
      " ..., \n",
      " [ 2.52895761  2.2327497   1.94511616 ...,  2.2276566   2.3350029\n",
      "   0.2551282 ]\n",
      " [ 3.19553018  2.68827271  1.56304419 ...,  4.25856066  3.73382998\n",
      "   0.25157806]\n",
      " [ 2.1421802   2.49942565  2.06357384 ...,  2.17940426  2.75782537\n",
      "   0.25999883]]\n"
     ]
    }
   ],
   "source": [
    "train_latent = generate_latent_space(autoencoder, rev_autoencoder, \n",
    "                                     image_vectors.loc[train_idx], textual_vectors.loc[train_idx])\n",
    "test_latent = generate_latent_space(autoencoder, rev_autoencoder, \n",
    "                                    image_vectors.loc[test_idx], textual_vectors.loc[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "000000491008.jpg    pizza\n",
       "000000402433.jpg    pizza\n",
       "000000025603.jpg    pizza\n",
       "000000385029.jpg    pizza\n",
       "000000047112.jpg    pizza\n",
       "000000260105.jpg    pizza\n",
       "000000306700.jpg    pizza\n",
       "000000179214.jpg    pizza\n",
       "000000357903.jpg    pizza\n",
       "000000547854.jpg    pizza\n",
       "dtype: object"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the classifier over the latent space: logistic regression + fully connected neural net\n",
    "base_df = pd.read_json(\"data/COCO/coco-easier.txt\", lines=True)\n",
    "categories = pd.Series(base_df[\"category\"].values, index=base_df[\"file_name\"].values)\n",
    "categories.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns the mean accuracy on the given test data and labels, in 5 cross validation splits\n",
    "scores = cross_val_score(classifier, \n",
    "                         pd.DataFrame(df[\"vectors\"].tolist()), \n",
    "                         df[\"category\"].values, \n",
    "                         cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(train_latent, categories[train_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92026578073089704"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(test_latent, categories[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
